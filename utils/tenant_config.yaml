tenant:
  ? ''
  : '{recurse:true}'
  '6774050634905226240':
    config:
      apiTokens:
        enabled: 'true'
      telemetry:
        enabled: 'false'
      v1:
        telemetry:
          enabled: 'true'
    v1:
      telemetry:
        enabled: 'true'
  '8794271414508985344':
    config:
      v1:
        dss:
          apiTokens:
            enabled: 'true'
  abansaldss:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          async_enabled: 'true'
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'false'
        skip_policy_scheduling: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_without_subscription: 'true'
    versions:
      fe: 4.1.334-es7
      worker:
        google: 3.13.41.gd.5297-dev
  abansales7:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        apps:
          msteams:
            tasks:
              activities_polling_interval: PT30S
              delta_fetch_interval: PT30S
              exposure_refresh_interval: PT1M
              message_polling_interval: PT30S
              subscriptions_renew_interval: PT10M
            webhooks:
              ignore_token_expiration: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          msteams:
            enabled: 'true'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(GnrrwXkxOuP9PtLr/QY0AsgTChfhHhER7VUMRqIxwDjvS+FJKH/NLw==)
        POSTGRES_SCHEMA_NAME: cs_abansales7
        POSTGRES_USER: ENC(NEagyhg4Tb3IRUHce9itB5WqhlBZHV1EpiIERcAtbDM=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_abansales7
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_abansales7
        MONGODB_TENANTDB_PWD: ENC(Ouf2S7yzl0GxCp8p1yQCN+qJ9O3ETmm3RuJQRutNuc6rKjrSiGVVoA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(gjjYusyRLgWEi0yrba4nIaLw5WXR2SAaY9R+GJR6X7Y=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_without_subscription: 'false'
    versions:
      fe: 4.1.399-es7
  alnupo10:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''alnupo10'')

          2020-02-28 19:48:28,753 MainThread spark-people-sort-alnupo10: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''alnupo10'')

          20/02/28 19:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:48:29 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_finance,subcategory=es_pci_perfi:306

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_legal,subcategory=es_merger_acquisition:91

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_legal,subcategory=es_patent_filings:51

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_legal,subcategory=es_standard_business_agreements:11598

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_ip,subcategory=es_source_code:5562

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_legal,subcategory=es_bankruptcy_filings:432

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo10,build=1.0.32.b145,migrated=True,tenant=alnupo10,category=es_finance,subcategory=es_pci_finac:489

          '
        pid: null
        result: alnupo10:analyze-ml, pid=25969 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\
          \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\
          \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\t\
          at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\
          \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1890)\n\tat\
          \ org.apache.spark.SparkContext.runJob(SparkContext.scala:1903)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1916)\n\
          \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1930)\n\tat\
          \ org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912)\n\tat\
          \ org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:911)\n\
          \tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\
          \tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest:\
          \ null\nc2NhbjsxOzgyMjMzMjg4NTc6VU5lU2xUWW5SRXFiUFdUOXBhem9WZzsxO3RvdGFsX2hpdHM6NDE3NTs=\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:427)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:385)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:375)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.scroll(RestClient.java:445)\n\
          \tat org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:436)\n\
          \tat org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:86)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.next(EsInputFormat.java:298)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.nextKeyValue(EsInputFormat.java:232)\n\
          \tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182)\n\
          \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)\n\
          \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\t\
          at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat\
          \ org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:120)\n\
          \tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:112)\n\
          \tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)\n\
          \tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)\n\
          \tat org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)\n\
          \tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1877)\n\
          \tat org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)\n\
          \n\n"
        pid: null
        result: alnupo10:domain-count, status=zombie, state=finished
        state: finished
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='alnupo10', use_elasticsearch=False)\n\
          2020-02-28 19:34:41,676 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo10/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:34:41,680 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo10/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:34:41,684 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo10/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:34:41,684 MainThread spark-people-sort-alnupo10:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='alnupo10', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:34:42 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:34:42 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:34:42\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\nfatal: Not a git repository (or any of the parent directories):\
          \ .git\nfatal: Not a git repository (or any of the parent directories):\
          \ .git\n\r[Stage 0:>                                                   \
          \     (0 + 36) / 36]\r[Stage 0:>                                       \
          \                 (0 + 36) / 36]\r[Stage 0:>                           \
          \                             (0 + 36) / 36]\r[Stage 0:>               \
          \                                         (0 + 36) / 36]\r[Stage 0:=>  \
          \                                                     (1 + 35) / 36]\r[Stage\
          \ 0:===>                                                     (2 + 34) /\
          \ 36]\r[Stage 0:====>                                                  \
          \  (3 + 33) / 36]\r[Stage 0:======>                                    \
          \              (4 + 32) / 36]\r[Stage 0:=======>                       \
          \                          (5 + 31) / 36]\r[Stage 0:===========>       \
          \                                      (7 + 29) / 36]\r[Stage 0:============>\
          \                                            (8 + 28) / 36]\r[Stage 0:==============>\
          \                                          (9 + 27) / 36]\r[Stage 0:===============>\
          \                                        (10 + 26) / 36]\r[Stage 0:=================>\
          \                                      (11 + 25) / 36]\r[Stage 0:==================>\
          \                                     (12 + 24) / 36]\r[Stage 0:====================>\
          \                                   (13 + 23) / 36]\r[Stage 0:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 0:=======================>\
          \                                (15 + 21) / 36]\r[Stage 0:========================>\
          \                               (16 + 20) / 36]\r[Stage 0:==========================>\
          \                             (17 + 19) / 36]\r[Stage 0:============================>\
          \                           (18 + 18) / 36]\r[Stage 0:=============================>\
          \                          (19 + 17) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:================================>\
          \                       (21 + 15) / 36]\r[Stage 0:==================================>\
          \                     (22 + 14) / 36]\r[Stage 0:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 0:======================================>\
          \                 (25 + 11) / 36]\r[Stage 0:========================================>\
          \               (26 + 10) / 36]\r[Stage 0:==========================================>\
          \              (27 + 9) / 36]\r[Stage 0:============================================>\
          \            (28 + 8) / 36]\r[Stage 0:=============================================>\
          \           (29 + 7) / 36]\r[Stage 0:===============================================>\
          \         (30 + 6) / 36]\r[Stage 0:=================================================>\
          \       (31 + 5) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 1:>                             \
          \                           (0 + 36) / 36]\r[Stage 1:>                 \
          \                                       (0 + 36) / 36]\r[Stage 1:>     \
          \                                                   (0 + 36) / 36]\r[Stage\
          \ 1:>                                                        (0 + 36) /\
          \ 36]\r[Stage 1:>                                                      \
          \  (0 + 36) / 36]\r[Stage 1:=>                                         \
          \              (1 + 35) / 36]\r[Stage 1:====>                          \
          \                          (3 + 33) / 36]\r[Stage 1:======>            \
          \                                      (4 + 32) / 36]\r[Stage 1:=======>\
          \                                                 (5 + 31) / 36]\r[Stage\
          \ 1:=========>                                               (6 + 30) /\
          \ 36]\r[Stage 1:===========>                                           \
          \  (7 + 29) / 36]\r[Stage 1:============>                              \
          \              (8 + 28) / 36]\r[Stage 1:==============>                \
          \                          (9 + 27) / 36]\r[Stage 1:===============>   \
          \                                     (10 + 26) / 36]\r[Stage 1:=================>\
          \                                      (11 + 25) / 36]\r[Stage 1:==================>\
          \                                     (12 + 24) / 36]\r[Stage 1:====================>\
          \                                   (13 + 23) / 36]\r[Stage 1:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 1:=======================>\
          \                                (15 + 21) / 36]\r[Stage 1:========================>\
          \                               (16 + 20) / 36]\r[Stage 1:============================>\
          \                           (18 + 18) / 36]\r[Stage 1:=============================>\
          \                          (19 + 17) / 36]\r[Stage 1:===============================>\
          \                        (20 + 16) / 36]\r[Stage 1:===================================>\
          \                    (23 + 13) / 36]\r[Stage 1:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 1:======================================>\
          \                 (25 + 11) / 36]\r[Stage 1:========================================>\
          \               (26 + 10) / 36]\r[Stage 1:==========================================>\
          \              (27 + 9) / 36]\r[Stage 1:===============================================>\
          \         (30 + 6) / 36]\r[Stage 1:=================================================>\
          \       (31 + 5) / 36]\r[Stage 1:====================================================>\
          \    (33 + 3) / 36]\r[Stage 1:=====================================================>\
          \   (34 + 2) / 36]\r                                                   \
          \                             \r\r[Stage 2:>                           \
          \                             (0 + 36) / 36]\r[Stage 2:>               \
          \                                         (0 + 36) / 36]\r[Stage 2:>   \
          \                                                     (0 + 36) / 36]\r[Stage\
          \ 2:>                                                        (0 + 36) /\
          \ 36]\r[Stage 2:>                                                      \
          \  (0 + 36) / 36], spark_master='local', tenant='alnupo10')\n"
        pid: ip-10-3-7-96.68841
        result: 'action: state=running'
        state: running
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          bulk_incidents: 'true'
          combined_visibility:
            enabled: 'true'
          multi_factor_authentication:
            enable: 'false'
          rbac_teams:
            enabled: 'true'
          saml_proxy:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_rta_processing: 'False'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(RCu7+tnTWHwK80uZ85jsZH00o8nS3W2UzwEBRTiPURNh+l3bVmvdJw==)
        POSTGRES_SCHEMA_NAME: cs_alnupo10
        POSTGRES_USER: ENC(A14GGjKOVRcgPkn2eTw4QQluirhNCP1Q8n7X8H7al5U=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_alnupo10
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_alnupo10
        MONGODB_TENANTDB_PWD: ENC(U4WSQhWD95jfOiaKY+lpuFtOcbFhWDZEyvc0xk1rnQKVcUJU/7+Cgg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(qPM4wWh9SChP+C28L5hyDOWGRTQjhIOU+ialMTJZQ3M=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.46.1869
      fe: 0.0.dss.822
      worker: 3.13.53.d1
  alnupo5:
    analytics:
      alnu21:
        ? ''
        : null
      alnupo10:
        ? ''
        : null
      alnupo2:
        ? ''
        : null
      alnupo21:
        ? ''
        : null
      alnupo3:
        ? ''
        : null
      alnupo30:
        ? ''
        : null
      alnupo31:
        ? ''
        : null
      alnupo5:
        ? ''
        : null
      alnupo6:
        ? ''
        : null
      alnupo7:
        ? ''
        : null
      alnupo8:
        ? ''
        : null
      alnupo9:
        ? ''
        : null
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''alnupo5'')

          2020-02-28 19:48:29,158 MainThread spark-people-sort-alnupo5: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''alnupo5'')

          20/02/28 19:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:48:30 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_finance,subcategory=es_pci_finac:256

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_finance,subcategory=es_pci_perfi:104

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_legal,subcategory=es_bankruptcy_filings:319

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_ip,subcategory=es_source_code:12666

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_legal,subcategory=es_merger_acquisition:8

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_legal,subcategory=es_patent_filings:11

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=alnupo5,build=1.0.32.b145,migrated=True,tenant=alnupo5,category=es_legal,subcategory=es_standard_business_agreements:188008

          '
        pid: null
        result: alnupo5:analyze-ml, pid=26193 bad process, setting state=unknown
        state: unknown
      ankur:
        ? ''
        : null
      aperturesamlauto:
        ? ''
        : null
      asivanadi:
        ? ''
        : null
      atftenant:
        ? ''
        : null
      autosamlazure:
        ? ''
        : null
      azureadauto:
        ? ''
        : null
      brenold:
        ? ''
        : null
      bright:
        ? ''
        : null
      brightr:
        ? ''
        : null
      dngo:
        ? ''
        : null
      dngo1:
        ? ''
        : null
      domain-count:
        ? ''
        : null
        $action: null
        log: 'INFO: {''domain'': u''paloaltonetworks.com'', ''user_count'': 11, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''outlook.com'', ''user_count'': 4, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''panwcirro.onmicrosoft.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''probeaperture.onmicrosoft.com'', ''user_count'': 1,
          ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''em.facebookmail.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''gmail.com'', ''user_count'': 15, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''aperturesamlauto.onmicrosoft.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''fbworkmail.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa.com'', ''user_count'': 18, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''tomigniteinc.onmicrosoft.com'', ''user_count'': 7,
          ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa3.onmicrosoft.com'', ''user_count'': 3,
          ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''go.surveymonkey.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''servicenow.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''cirrosecure.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''trbvn.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''bettercloud.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''garlic.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''paloaltonetwors.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa2.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''example.com'', ''user_count'': 574, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''sns.amazonaws.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''slack.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''facebook.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa3.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''now.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''cirrotester.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''hotmail.com'', ''user_count'': 2, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''washingtonpost.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''xoriant.com'', ''user_count'': 2, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''salesforce.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureatf.onmicrosoft.com'', ''user_count'': 1,
          ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''amazon.com'', ''user_count'': 2, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa1.com'', ''user_count'': 4, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''mail.salesforce.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apacprobeaperture.onmicrosoft.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''aperturesamlqa.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''euprobeaperture.onmicrosoft.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''yahoo.com'', ''user_count'': 2, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''atlassianevents.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''google.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''smartsheet.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''microsoft.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''qq.com'', ''user_count'': 1, ''external'': True, ''cs_user'':
          ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureatf.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''businesshangouts.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@alnupo5.com''}

          INFO: {''domain'': u''apertureqa.onmicrosoft.com'', ''user_count'': 13,
          ''external'': True, ''cs_user'': ''service@alnupo5.com''}

          INFO: #domains=48

          2018-05-17 18:34:15,106 spark-domain-count-alnupo5: INFO: user-counts-by-domain:
          time to process people table=0.81

          2018-05-17 18:34:15,107 spark-domain-count-alnupo5: INFO: user-counts-by-domain:
          time to write to mongo/elasticsearch=0.05

          2018-05-17 18:34:15,107 spark-domain-count-alnupo5: INFO: user-counts-by-domain.interval=0.86

          '
        pid: null
        result: alnupo5:domain-count, pid=99017 bad process, setting state=unknown
        state: unknown
      es6harsh:
        ? ''
        : null
      esbackup:
        ? ''
        : null
      evident:
        ? ''
        : null
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      fe:
        ? ''
        : null
      goku:
        ? ''
        : null
      gvargas:
        ? ''
        : null
      jliu:
        ? ''
        : null
      jpan1:
        ? ''
        : null
      jtest1:
        ? ''
        : null
      jtest2:
        ? ''
        : null
      jtest3:
        ? ''
        : null
      jtest4:
        ? ''
        : null
      jtest5:
        ? ''
        : null
      krish:
        ? ''
        : null
      krishpo:
        ? ''
        : null
      leijiang:
        ? ''
        : null
      leijiang2:
        ? ''
        : null
      lit10221:
        ? ''
        : null
      liwei:
        ? ''
        : null
      liwei_stg2:
        ? ''
        : null
      liweicontrast:
        ? ''
        : null
      liweistg2:
        ? ''
        : null
      megazuread:
        ? ''
        : null
      megbox2:
        ? ''
        : null
      megbox4:
        ? ''
        : null
      megpingone:
        ? ''
        : null
      megr31:
        ? ''
        : null
      megr31azure:
        ? ''
        : null
      megr32:
        ? ''
        : null
      megr33:
        ? ''
        : null
      megsaml:
        ? ''
        : null
      mitali:
        ? ''
        : null
      mitaligcp:
        ? ''
        : null
      mongobackup:
        ? ''
        : null
      monkas:
        ? ''
        : null
      munnabhai2:
        ? ''
        : null
      mytenant:
        ? ''
        : null
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='alnupo5', use_elasticsearch=False)\n\
          2020-02-28 19:43:58,203 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo5/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:43:58,208 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo5/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:43:58,213 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/alnupo5/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:43:58,214 MainThread spark-people-sort-alnupo5:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='alnupo5', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:43:58 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:43:59 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:43:59\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:43:59 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:43:59 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:43:59 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:43:59 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\n\r[Stage 0:>               \
          \                                         (0 + 36) / 36]\r[Stage 0:>   \
          \                                                     (0 + 36) / 36]\r[Stage\
          \ 0:=>                                                       (1 + 35) /\
          \ 36]\r[Stage 0:===>                                                   \
          \  (2 + 34) / 36]\r[Stage 0:====>                                      \
          \              (3 + 33) / 36]\r[Stage 0:======>                        \
          \                          (4 + 32) / 36]\r[Stage 0:=======>           \
          \                                      (5 + 31) / 36]\r[Stage 0:===========>\
          \                                             (7 + 29) / 36]\r[Stage 0:============>\
          \                                            (8 + 28) / 36]\r[Stage 0:==============>\
          \                                          (9 + 27) / 36]\r[Stage 0:=================>\
          \                                      (11 + 25) / 36]\r[Stage 0:==================>\
          \                                     (12 + 24) / 36]\r[Stage 0:====================>\
          \                                   (13 + 23) / 36]\r[Stage 0:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 0:=======================>\
          \                                (15 + 21) / 36]\r[Stage 0:========================>\
          \                               (16 + 20) / 36]\r[Stage 0:==========================>\
          \                             (17 + 19) / 36]\r[Stage 0:============================>\
          \                           (18 + 18) / 36]\r[Stage 0:=============================>\
          \                          (19 + 17) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:================================>\
          \                       (21 + 15) / 36]\r[Stage 0:==================================>\
          \                     (22 + 14) / 36]\r[Stage 0:===================================>\
          \                    (23 + 13) / 36]\r[Stage 0:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 0:======================================>\
          \                 (25 + 11) / 36]\r[Stage 0:========================================>\
          \               (26 + 10) / 36]\r[Stage 0:==========================================>\
          \              (27 + 9) / 36]\r[Stage 0:=================================================>\
          \       (31 + 5) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r[Stage 0:=========================================================(36\
          \ + 0) / 36]\r                                                         \
          \                       \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: alnupo5:people-sort, pid=93019 bad process, setting state=unknown
        state: unknown
      prateik1:
        ? ''
        : null
      praveen1:
        ? ''
        : null
      probe:
        ? ''
        : null
      probe_csstg:
        ? ''
        : null
      probecss:
        ? ''
        : null
      probecsst2g:
        ? ''
        : null
      probecsstg:
        ? ''
        : null
      probecsstg2:
        ? ''
        : null
      prod1r26:
        ? ''
        : null
      prod2r26:
        ? ''
        : null
      psjh:
        ? ''
        : null
      ptrehanaz:
        ? ''
        : null
      ptrehanaz2:
        ? ''
        : null
      ptrehanaz4:
        ? ''
        : null
      qarepo:
        ? ''
        : null
      r25alpha:
        ? ''
        : null
      r26prod:
        ? ''
        : null
      r27licenseqa:
        ? ''
        : null
      r29alphaapac:
        ? ''
        : null
      r29alphaeu:
        ? ''
        : null
      r29prod:
        ? ''
        : null
      r30hfverify:
        ? ''
        : null
      r30hfverify1:
        ? ''
        : null
      rails5:
        ? ''
        : null
      rakurati-test:
        ? ''
        : null
      rakurati1:
        ? ''
        : null
      rakurati2:
        ? ''
        : null
      rakurati3:
        ? ''
        : null
      ramya:
        ? ''
        : null
      ramyatest:
        ? ''
        : null
      ramyatest23:
        ? ''
        : null
      ramyathula:
        ? ''
        : null
      ramyathulademo:
        ? ''
        : null
      ror5:
        ? ''
        : null
      ru24t1:
        ? ''
        : null
      ru24t10:
        ? ''
        : null
      ru24t11:
        ? ''
        : null
      ru24t13:
        ? ''
        : null
      ru24t15:
        ? ''
        : null
      ru24t16:
        ? ''
        : null
      ru24t2:
        ? ''
        : null
      ru24t3:
        ? ''
        : null
      ru24t5:
        ? ''
        : null
      ru24t6:
        ? ''
        : null
      ru24t7:
        ? ''
        : null
      ru3:
        ? ''
        : null
      s3large:
        ? ''
        : null
      s3migrate1:
        ? ''
        : null
      s3small:
        ? ''
        : null
      samlapiauto:
        ? ''
        : null
      samlauto:
        ? ''
        : null
      samlazureadauto:
        ? ''
        : null
      samlfw2:
        ? ''
        : null
      sdutta:
        ? ''
        : null
      selftest:
        ? ''
        : null
      shanna:
        ? ''
        : null
      simondocker:
        ? ''
        : null
      spnbootstrap2:
        ? ''
        : null
      spnbootstrap3:
        ? ''
        : null
      suhas:
        ? ''
        : null
      suhas2cs:
        ? ''
        : null
      suhascs:
        ? ''
        : null
      suhascs3:
        ? ''
        : null
      suhascs4:
        ? ''
        : null
      suhascs5:
        ? ''
        : null
      suhascs6:
        ? ''
        : null
      suhasg:
        ? ''
        : null
      suhastp:
        ? ''
        : null
      sumittest:
        ? ''
        : null
      supadhya:
        ? ''
        : null
      supadhya2:
        ? ''
        : null
      techpubnew:
        ? ''
        : null
      test:
        ? ''
        : null
      test10382:
        ? ''
        : null
      testlicense1:
        ? ''
        : null
      testlicense2:
        ? ''
        : null
      testlicense3:
        ? ''
        : null
      tomr:
        ? ''
        : null
      tomr2:
        ? ''
        : null
      tomrioux:
        ? ''
        : null
      trioux:
        ? ''
        : null
      ubangaloreautopo:
        ? ''
        : null
      ubautomation:
        ? ''
        : null
      ubazureauto:
        ? ''
        : null
      uttamazuretest:
        ? ''
        : null
      uttamazuretest1:
        ? ''
        : null
      viraj:
        ? ''
        : null
      whatever:
        ? ''
        : null
      ycheng:
        ? ''
        : null
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'false'
    config:
      v1:
        REMEDIATION_API_CALL_LIMIT: '10000'
        app_migrations:
          office365_3502ae207927e39a54d23926bf80771e_migrated: 'true'
        config:
          ? ''
          : null
          v1:
            ? ''
            : null
            lock_timeout: '2'
            should_write_dedup_stacktrace: 'true'
            task_dedup_enabled: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          aperture-dss:
            dp_worker_dedup_enabled: 'true'
          dss-enabled: 'false'
        fe:
          assets_search:
            ? ''
            : null
            fast_mode: 'true'
          async_download:
            ? ''
            : null
            enabled: 'true'
          file_properties:
            enabled: 'true'
          group_based_policies:
            enabled: 'true'
          group_based_visibility:
            enabled: 'true'
          health_check:
            enabled: 'true'
          memory_usage:
            ? ''
            : null
            enable: 'true'
          multi_factor_authentication:
            enable: 'false'
          piwik:
            ? ''
            : null
            enable: 'true'
          rbac:
            enabled: 'true'
          rbac_teams:
            enabled: 'true'
          secure_headers:
            enabled: 'false'
          service_discovery:
            ? ''
            : null
            custom_tags: dashboard:es7x/data-pattern:es7x/remediation:es7x/data-policy-violation:es7x
            enabled: 'true'
        incidents:
          ? ''
          : null
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        lock_timeout: '2'
        num_office365_od_metadata_forward_scan_threads: '5'
        should_write_dedup_stacktrace: 'true'
        task_dedup_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          awsconsole:
            job_interval_in_min: '10'
            service_discovery_job_interval_in_min: '10'
          dropbox:
            ? ''
            : null
            RATE_LIMIT_MAX_ATTEMPTS: '20'
            RATE_LIMIT_PER_SECOND: '20'
            RATE_LIMIT_WAIT_TIME_IN_MS: '1000'
            number_of_folders_to_fetch: '1000'
          office365:
            ? ''
            : null
            page_size: '200'
            pages_processed_per_user: '2'
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(M//2ZFTDb+B1FHitQEX9TB4PsYKNKfxdysptYf84lfqzeV5HqvvoEg==)
        POSTGRES_SCHEMA_NAME: cs_alnupo5
        POSTGRES_USER: ENC(mEjvLJnQYOEsgDzkHix9tgbaplsxRDYdqdHSj7YvlW0=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_alnupo5
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_alnupo5
        MONGODB_TENANTDB_PWD: ENC(OGZMknzo8KPdVwO6kMt5LYbOm4qj2OBnXI/OFPGmurKEaZAzdPP/fg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(pXKJgg7SuMyAmL2RkZbMRFJV22OKeqRZSiQtUehZaJg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.125.4
      fe: 4.1.415-es7
      worker: 3.13.99.d10
  amrynskyi7x:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(dtcPL7I8wmz6RNd4xCavzV9d9G7No+gi7bwmcu//s81tbANkuWbNwQ==)
        POSTGRES_SCHEMA_NAME: cs_amrynskyi7x
        POSTGRES_USER: ENC(bqDsU/UlQ3litxR4cLI6P/W3DyWpPLKaaVcSn6NxRR8=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_amrynskyi7x
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_amrynskyi7x
        MONGODB_TENANTDB_PWD: ENC(hroU59ojA6wCEuUoGZao+9Xoo8AJ1eScIcVCRszKl7vZJVZYru7kGg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(Y++qTPy1hFts2iPqKY3IHgOKAd/gh0nr5xiQH7+sEfY=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ankur22:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          cloudapp_health_metrics:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'false'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          queuecriteria:
            peak_hours_scan_disabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  apionlyplusinline:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  argon:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  atfmultidev:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(t6RNgg7jMieV6uDLLXfNqS7cYuxHdnUkl8Qr+P7TVkuvp+zWgH7qAw==)
        POSTGRES_SCHEMA_NAME: cs_atfmultidev
        POSTGRES_USER: ENC(cSLNWqRCkgd4XI8c+egdT366KOJCU/T6ZPKsBClrqhc=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_atfmultidev
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_atfmultidev
        MONGODB_TENANTDB_PWD: ENC(dZB5Iatue1tdVgPZck7hn0X/MTCWcKCaNFo0u6dHmgT9uTh7+7vFew==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(8tgiwJ9GiJt5KZ0jpqfBZCBBP3hxT8XzjZ+BvUJYB/Q=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  atfstg2:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:44:03 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:44:03 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:44:03\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:44:03 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:44:03 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:44:03 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:44:03 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:44:03\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:44:03 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:44:03 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:44:03 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:44:03 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:44:03\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:44:03 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: atfstg2:analyze-ml, pid=94143 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "    \"atfstg2.com\", \n    \"webex.bot\", \n    \"apertureqa.com\",\
          \ \n    \"cirrotest.com\", \n    \"probe.com\", \n    \"probeapertureus.com\"\
          , \n    \"probecsstg.com\", \n    \"apertureatf.onmicrosoft.com\", \n  \
          \  \"apertureatf.com\"\n]\n20/02/28 19:44:25 WARN EsInputFormat: Cannot\
          \ determine task id...\nINFO: writing 31 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@atfstg2.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'paloaltonetworks.com', 'user_count': 7, 'external': True,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'external.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain':\
          \ u'apertureatf.onmicrosoft.com', 'user_count': 106, 'external': False,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'apertureperf1.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'box.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'atftenant.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@atfstg2.com'}\nINFO: {'domain': u'apertureqa3.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'apertureqa.com',\
          \ 'user_count': 45, 'external': False, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apollo10.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@atfstg2.com'}\nINFO: {'domain': u'gjdgf.com', 'user_count': 1,\
          \ 'external': True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain':\
          \ u'apertureqa3.com', 'user_count': 3, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apertureperf.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'sharefile.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apertureqa2.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'probecsstg.com',\
          \ 'user_count': 1, 'external': False, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'probeapertureus.com', 'user_count': 1, 'external': False,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'prismasaasdev.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'probe.com', 'user_count': 4, 'external': False, 'cs_user':\
          \ 'service@atfstg2.com'}\nINFO: {'domain': u'cirrotester.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain':\
          \ u'ygfdsid.ss', 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'sf-notifications.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'gmail.com', 'user_count':\
          \ 66, 'external': True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain':\
          \ u'cirrotests.com', 'user_count': 2, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'mkm.mkm', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@atfstg2.com'}\nINFO: {'domain': u'apertureatf.com', 'user_count':\
          \ 9, 'external': False, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain':\
          \ u'selftest.com', 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'apertureperf1.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@atfstg2.com'}\nINFO: {'domain': u'lpl.lpl',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2.com'}\n\
          INFO: {'domain': u'citrix.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@atfstg2.com'}\nINFO: #domains=31\n2020-02-28 19:44:26,196 MainThread\
          \ spark-domain-count-atfstg2: INFO: user-counts-by-domain: time to process\
          \ people table=1.02\n2020-02-28 19:44:26,197 MainThread spark-domain-count-atfstg2:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:44:26,197 MainThread spark-domain-count-atfstg2: INFO: user-counts-by-domain.interval=1.03\n"
        pid: null
        result: atfstg2:domain-count, pid=94054 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='atfstg2', use_elasticsearch=False)\n\
          2020-02-28 19:31:30,676 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:31:30,682 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:31:30,689 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:31:30,690 MainThread spark-people-sort-atfstg2:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='atfstg2', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:31:31 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:31:32 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:31:32\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:31:32 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\n\r[Stage 0:>               \
          \                                         (0 + 36) / 36]\r[Stage 0:===>\
          \                                                     (2 + 34) / 36]\r[Stage\
          \ 0:============>                                            (8 + 28) /\
          \ 36]\r[Stage 0:=================>                                     \
          \ (11 + 25) / 36]\r[Stage 0:===============================>           \
          \             (20 + 16) / 36]\r[Stage 0:============================================>\
          \            (28 + 8) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 1:>                             \
          \                           (0 + 36) / 36]\r[Stage 1:======>           \
          \                                       (4 + 32) / 36]\r[Stage 1:===========>\
          \                                             (7 + 29) / 36]\r[Stage 1:=================>\
          \                                      (11 + 25) / 36]\r[Stage 1:============================>\
          \                           (18 + 18) / 36]\r[Stage 1:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 1:==========================================>\
          \              (27 + 9) / 36]\r[Stage 1:===============================================>\
          \         (30 + 6) / 36]\r[Stage 1:=================================================>\
          \       (31 + 5) / 36]\r[Stage 1:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 2:>                             \
          \                           (0 + 36) / 36]\r[Stage 2:=>                \
          \                                       (1 + 35) / 36]\r[Stage 2:===>  \
          \                                                   (2 + 34) / 36]\r[Stage\
          \ 2:====>                                                    (3 + 33) /\
          \ 36]\r[Stage 2:============>                                          \
          \  (8 + 28) / 36]\r[Stage 2:=================>                         \
          \             (11 + 25) / 36]\r[Stage 2:==================>            \
          \                         (12 + 24) / 36]\r[Stage 2:=======================>\
          \                                (15 + 21) / 36]\r[Stage 2:============================>\
          \                           (18 + 18) / 36]\r[Stage 2:==================================>\
          \                     (22 + 14) / 36]\r[Stage 2:===================================>\
          \                    (23 + 13) / 36]\r[Stage 2:======================================>\
          \                 (25 + 11) / 36]\r[Stage 2:============================================>\
          \            (28 + 8) / 36]\r[Stage 2:=====================================================>\
          \   (34 + 2) / 36]\r                                                   \
          \                             \r\r[Stage 3:>                           \
          \                             (0 + 36) / 36]\r[Stage 3:>               \
          \                                         (0 + 36) / 36]\r[Stage 3:=>  \
          \                                                     (1 + 35) / 36]\r[Stage\
          \ 3:===>                                                     (2 + 34) /\
          \ 36]\r[Stage 3:====>                                                  \
          \  (3 + 33) / 36]\r[Stage 3:======>                                    \
          \              (4 + 32) / 36]\r[Stage 3:=========>                     \
          \                          (6 + 30) / 36]\r[Stage 3:===========>       \
          \                                      (7 + 29) / 36]\r[Stage 3:============>\
          \                                            (8 + 28) / 36]\r[Stage 3:==============>\
          \                                          (9 + 27) / 36]\r[Stage 3:===============>\
          \                                        (10 + 26) / 36]\r[Stage 3:=================>\
          \                                      (11 + 25) / 36]\r[Stage 3:====================>\
          \                                   (13 + 23) / 36]\r[Stage 3:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 3:=======================>\
          \                                (15 + 21) / 36]\r[Stage 3:========================>\
          \                               (16 + 20) / 36]\r[Stage 3:==========================>\
          \                             (17 + 19) / 36]\r[Stage 3:=============================>\
          \                          (19 + 17) / 36]\r[Stage 3:===============================>\
          \                        (20 + 16) / 36]\r[Stage 3:================================>\
          \                       (21 + 15) / 36]\r[Stage 3:==================================>\
          \                     (22 + 14) / 36]\r[Stage 3:===================================>\
          \                    (23 + 13) / 36]\r[Stage 3:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 3:======================================>\
          \                 (25 + 11) / 36]\r[Stage 3:========================================>\
          \               (26 + 10) / 36]\r[Stage 3:==========================================>\
          \              (27 + 9) / 36]\r[Stage 3:============================================>\
          \            (28 + 8) / 36]\r[Stage 3:=============================================>\
          \           (29 + 7) / 36]\r[Stage 3:===============================================>\
          \         (30 + 6) / 36]\r[Stage 3:=================================================>\
          \       (31 + 5) / 36]\r[Stage 3:==================================================>\
          \      (32 + 4) / 36]\r[Stage 3:====================================================>\
          \    (33 + 3) / 36]\r[Stage 3:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 3:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 4:>                             \
          \                           (0 + 36) / 36]\r[Stage 4:>                 \
          \                                       (0 + 36) / 36]\r[Stage 4:>     \
          \                                                   (0 + 36) / 36]\r[Stage\
          \ 4:>                                                        (0 + 36) /\
          \ 36]\r[Stage 4:=>                                                     \
          \  (1 + 35) / 36]\r[Stage 4:===>                                       \
          \              (2 + 34) / 36]\r[Stage 4:====>                          \
          \                          (3 + 33) / 36]\r[Stage 4:=======>           \
          \                                      (5 + 31) / 36]\r[Stage 4:===========>\
          \                                             (7 + 29) / 36]\r[Stage 4:============>\
          \                                            (8 + 28) / 36]\r[Stage 4:==============>\
          \                                          (9 + 27) / 36]\r[Stage 4:===============>\
          \                                        (10 + 26) / 36]\r[Stage 4:=================>\
          \                                      (11 + 25) / 36]\r[Stage 4:==================>\
          \                                     (12 + 24) / 36]\r[Stage 4:====================>\
          \                                   (13 + 23) / 36]\r[Stage 4:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 4:=======================>\
          \                                (15 + 21) / 36]\r[Stage 4:========================>\
          \                               (16 + 20) / 36]\r[Stage 4:==========================>\
          \                             (17 + 19) / 36]\r[Stage 4:============================>\
          \                           (18 + 18) / 36]\r[Stage 4:===============================>\
          \                        (20 + 16) / 36]\r[Stage 4:================================>\
          \                       (21 + 15) / 36]\r[Stage 4:==================================>\
          \                     (22 + 14) / 36]\r[Stage 4:===================================>\
          \                    (23 + 13) / 36]\r[Stage 4:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 4:======================================>\
          \                 (25 + 11) / 36]\r[Stage 4:========================================>\
          \               (26 + 10) / 36]\r[Stage 4:==========================================>\
          \              (27 + 9) / 36]\r[Stage 4:============================================>\
          \            (28 + 8) / 36]\r[Stage 4:=============================================>\
          \           (29 + 7) / 36]\r[Stage 4:===============================================>\
          \         (30 + 6) / 36]\r[Stage 4:==================================================>\
          \      (32 + 4) / 36]\r[Stage 4:====================================================>\
          \    (33 + 3) / 36]\r[Stage 4:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 5:>                             \
          \                           (0 + 36) / 36]\r[Stage 5:>                 \
          \                                       (0 + 36) / 36]\r[Stage 5:>     \
          \                                                   (0 + 36) / 36]\r[Stage\
          \ 5:>                                                        (0 + 36) /\
          \ 36]\r[Stage 5:>                                                      \
          \  (0 + 36) / 36]\r[Stage 5:=>                                         \
          \              (1 + 35) / 36]\r[Stage 5:===>                           \
          \                          (2 + 34) / 36]\r[Stage 5:====>              \
          \                                      (3 + 33) / 36]\r[Stage 5:======>\
          \                                                  (4 + 32) / 36]\r[Stage\
          \ 5:=======>                                                 (5 + 31) /\
          \ 36]\r[Stage 5:===========>                                           \
          \  (7 + 29) / 36]\r[Stage 5:==============>                            \
          \              (9 + 27) / 36]\r[Stage 5:=================>             \
          \                         (11 + 25) / 36]\r[Stage 5:==================>\
          \                                     (12 + 24) / 36]\r[Stage 5:====================>\
          \                                   (13 + 23) / 36]\r[Stage 5:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 5:=======================>\
          \                                (15 + 21) / 36]\r[Stage 5:==========================>\
          \                             (17 + 19) / 36]\r[Stage 5:=============================>\
          \                          (19 + 17) / 36]\r[Stage 5:===============================>\
          \                        (20 + 16) / 36]\r[Stage 5:================================>\
          \                       (21 + 15) / 36]\r[Stage 5:==================================>\
          \                     (22 + 14) / 36]\r[Stage 5:===================================>\
          \                    (23 + 13) / 36]\r[Stage 5:======================================>\
          \                 (25 + 11) / 36]\r[Stage 5:========================================>\
          \               (26 + 10) / 36]\r[Stage 5:==========================================>\
          \              (27 + 9) / 36]\r[Stage 5:============================================>\
          \            (28 + 8) / 36]\r[Stage 5:=============================================>\
          \           (29 + 7) / 36]\r[Stage 5:=================================================>\
          \       (31 + 5) / 36]\r[Stage 5:====================================================>\
          \    (33 + 3) / 36]\r[Stage 5:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 5:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \r\r[Stage 6:>                             \
          \                           (0 + 36) / 36]\r[Stage 6:>                 \
          \                                       (0 + 36) / 36]\r[Stage 6:>     \
          \                                                   (0 + 36) / 36]\r[Stage\
          \ 6:>                                                        (0 + 36) /\
          \ 36]\r[Stage 6:>                                                      \
          \  (0 + 36) / 36]"
        pid: ip-10-3-7-96.17757
        result: 'action: state=running'
        state: running
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        app_migrations:
          office365_25cda5daa6bef2c693c9fb7f2a62418a_migrated: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          auto_assign_incidents:
            enabled: 'true'
          group_based_policies:
            enabled: 'true'
          group_based_visibility:
            enabled: 'true'
        group_based_policies:
          enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          ? ''
          : null
          google:
            ? ''
            : null
            max_api_calls_per_unit: '2'
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(P8f1lD9p5RH/0UhMAtay8250aanZhGOvZskrImrDSylH/6p8W+LHbw==)
        POSTGRES_SCHEMA_NAME: cs_atfstg2
        POSTGRES_USER: ENC(VFC0CTvgpkScX+BIIgq4+j+kjKUHnT7sti/HKZp+h2g=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_atfstg2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_atfstg2
        MONGODB_TENANTDB_PWD: ENC(LsF/a1+FGE6JGXDCTNCs9l4X/Th9PNzh9QoH2T92uoF8m7zc3ystQQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(xhIv/kRrhvTqmBgQSdLP1DCa1vVG8UtsmkMSUhfk5Pc=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.215
      worker: 3.13.68.3837-dev
  atfstg2es7:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:45:30 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:45:30 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:45:30\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:45:30 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:45:30 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:45:30 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:45:30 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:45:30\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:45:30 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:45:30 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:45:30 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:45:30 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:45:30\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:45:30 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: atfstg2es7:analyze-ml, pid=116171 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:48:35 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"atfstg2es7.com\"\
          , \n    \"probe.com\", \n    \"probeapertureus.com\", \n    \"probecsstg.com\"\
          , \n    \"apertureatf.onmicrosoft.com\", \n    \"webex.bot\", \n    \"apertureatf.com\"\
          \n]\n20/02/28 19:48:36 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:48:36 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 3:=============================>                             (1 + 1) /\
          \ 2]\r                                                                 \
          \               \rINFO: writing 9 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@atfstg2es7.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'probeapertureus.com', 'user_count': 1, 'external': False,\
          \ 'cs_user': 'service@atfstg2es7.com'}\nINFO: {'domain': u'paloaltonetworks.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@atfstg2es7.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@atfstg2es7.com'}\nINFO: {'domain': u'gmail.com',\
          \ 'user_count': 5, 'external': True, 'cs_user': 'service@atfstg2es7.com'}\n\
          INFO: {'domain': u'apertureqa3.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@atfstg2es7.com'}\nINFO: {'domain': u'apertureqa1.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@atfstg2es7.com'}\n\
          INFO: {'domain': u'prismasaasdev.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@atfstg2es7.com'}\nINFO: {'domain': u'apertureatf.com',\
          \ 'user_count': 2, 'external': False, 'cs_user': 'service@atfstg2es7.com'}\n\
          INFO: {'domain': u'apertureqa.com', 'user_count': 3, 'external': True, 'cs_user':\
          \ 'service@atfstg2es7.com'}\nINFO: #domains=9\n2020-02-28 19:49:01,455 MainThread\
          \ spark-domain-count-atfstg2es7: INFO: user-counts-by-domain: time to process\
          \ people table=25.52\n2020-02-28 19:49:01,455 MainThread spark-domain-count-atfstg2es7:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:49:01,455 MainThread spark-domain-count-atfstg2es7: INFO:\
          \ user-counts-by-domain.interval=25.53\n"
        pid: null
        result: atfstg2es7:domain-count, pid=26808 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''atfstg2es7'', use_elasticsearch=False)

          2020-02-28 19:48:16,846 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2es7/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:48:16,850 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2es7/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:48:16,853 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/atfstg2es7/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:48:16,854 MainThread spark-people-sort-atfstg2es7: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''atfstg2es7'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:48:17 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:48:17 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:48:17 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:48:17 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: atfstg2es7:people-sort, pid=23342 bad process, setting state=unknown
        state: unknown
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        apps:
          msteams:
            ? ''
            : null
            tasks:
              ? ''
              : null
              activities_polling_interval: PT30S
              delta_fetch_interval: PT10S
              exposure_refresh_interval: PT1M
              message_polling_interval: PT10S
              subscriptions_renew_interval: PT1M
        aws_creds: '{"aws_access_key_id" : "",

          "aws_secret_access_key" : "",

          "aws_session_token" : "",

          "aws_security_token" : ""

          }'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          bitbucket:
            ? ''
            : null
            enabled: 'true'
          msteams:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_rta_processing: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(gZXTS9sV2KfhCJjHhe/1ShcinY0BlYjMH8uSSmDf/o9w/UIDI4OS1g==)
        POSTGRES_SCHEMA_NAME: cs_atfstg2es7
        POSTGRES_USER: ENC(oWRUlhKMPedl8BpuHY+EwdpQEJ3HpzleQS2UjeeISH8=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_atfstg2es7
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_atfstg2es7
        MONGODB_TENANTDB_PWD: ENC(E8YymYCrNutB+xRq5/AzmmKEWO3N/KgQSXwdZJxfe44MBofxm1okwg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(vdcZWpCLfJxlPp2qaCPFXjOn2+H235udkmqvkhJg05U=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: ip-10-3-0-76.ec2.internal
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.slack.659
      worker: 3.es7.13.132.d1
  bzhang:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:44:04 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:44:04 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:44:04\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:44:04 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:44:04 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:44:04 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:44:04 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:44:04\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:44:04 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:44:04 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:44:04 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:44:04 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:44:04\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:44:04 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: bzhang:analyze-ml, pid=94294 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.82325
        result: 'action: state=running'
        state: running
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='bzhang', use_elasticsearch=False)\n\
          2020-02-28 19:50:54,592 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/bzhang/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:50:54,598 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/bzhang/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:50:54,602 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/bzhang/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:50:54,602 MainThread spark-people-sort-bzhang:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='bzhang', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:50:55 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:50:55 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:50:55\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:50:55 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:50:55 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          fatal: Not a git repository (or any of the parent directories): .git\nfatal:\
          \ Not a git repository (or any of the parent directories): .git\n\r[Stage\
          \ 0:>                                                         (0 + 0) /\
          \ 36]\r[Stage 0:>                                                      \
          \  (0 + 36) / 36]\r[Stage 0:=============================>             \
          \             (19 + 17) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:==================================>\
          \                     (22 + 14) / 36]\r[Stage 0:========================================>\
          \               (26 + 10) / 36]\r[Stage 0:==========================================>\
          \              (27 + 9) / 36]\r[Stage 0:===============================================>\
          \         (30 + 6) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r                                                  \
          \                              \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: ip-10-3-7-96.64012
        result: bzhang:people-sort, pid=64012 bad process, setting state=unknown
        state: unknown
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        SEND_NOTIFICATION_DIGEST_EMAIL_WITHOUT_INCIDENTS: 'True'
        app_migrations:
          office365_851e670a58e6b1a1a40fa2a4af256fb3_migrated: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          delay_wildfire_submission_sec: '100'
          enable_async_incident_creation: 'false'
          enable_display_entire_syslog: 'true'
          enable_incident_detailed_log: 'true'
          enable_resolved_violation_filter: 'false'
          enable_syslog_enhancement: 'true'
          enable_syslog_enhancement_policy_id: 'true'
          incidentevent_asset_person_collaborator_count: '100'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
          skip_existing_violation_filter_dp_list: 60e5e300a81e281b6a6329de
          webex_bot_message_log: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'false'
          ocr-enabled: 'true'
        enable_policy_evaluation_logs: 'true'
        fe:
          cloudapp_health_metrics:
            enabled: 'true'
          health_metrics:
            enabled: 'true'
            show_recent_scans: 'true'
          office365:
            use_special_client_id: 'false'
          pan_sso:
            enabled: 'false'
        group_based_policies:
          enabled: 'true'
        health_metrics:
          emails: bzhang@paloaltonetworks.com
          syslog_enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        servicenow:
          enable_concurrent_api_calls: 'true'
        services:
          dashboard-service:
            ? ''
            : null
            collaborators_stats_time_range: '7'
            users_stats_time_range: '7'
          directory-service:
            directory_refresh_delay_hours: '0'
        skip_policy_scheduling: 'false'
        skip_rta_processing: 'False'
        syslog:
          enable_incident_asset_create_time: 'true'
          enable_syslog_details_in_log: 'true'
        versions:
          worker_tag: es7x
        wfm:
          enabled: 'true'
          expanded_types_enabled: 'true'
          malware_analysis_status_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          office365:
            O365_SELECTIVE_SCAN_CHECK_INTERVAL: '0'
          salesforce:
            refresh_exposure_files_in_days: '30'
            refresh_exposure_job_interval_in_hours: '24'
          sharepoint_site_refresh_exposure_cycle_in_hours: '0'
          whitelisted_ips: null
          worker:
            servicenow:
              skip_file_cache_remediation_download: 'true'
    data-pattern:
      skip_existing_violation_filter_dp_list: '1123'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(nIqXVd9CO8VOIdUmgGDinh/nGk3dGhKThws50KhokaR5R/fHlDn/UA==)
        POSTGRES_SCHEMA_NAME: cs_bzhang
        POSTGRES_USER: ENC(vCOohjXKtsWVl3RaHLOgtJfLjgUha6s0i3b3gDWI38o=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_bzhang
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_bzhang
        MONGODB_TENANTDB_PWD: ENC(dylBFZDfxNKXkek69Vb/pmxvoMp5QmtqqjeEhoQpTnde3K4s9juWDg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(fLBeYNEfdL0P+ArImfMX3IqRYnS6a82YSuM+DF5WiqM=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_metadata_from_dp_results: 'true'
    fetch_snippets_without_subscription: 'false'
    versions:
      fe: 4.1.474-es7
      worker: 3.13.41.5586-dev
  casbpae1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  clchavez:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'false'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'False'
          sspm:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(7I7YbrV6z7e9+at+Zz8ETRBfTh3DBOgfexAs3KenWkwwZfrphwmHgQ==)
        POSTGRES_SCHEMA_NAME: cs_clchavez
        POSTGRES_USER: ENC(Ax6uyuheJ4nj9R04tOiwdcGmvPxdebifgcLecZni7sc=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_clchavez
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_clchavez
        MONGODB_TENANTDB_PWD: ENC(LW9Rd4YJoqlkwl47v4LwmeBnhYOt/gxuQD8IFdpZt5P3CpwM7AleBA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(+IGt7F7wUFTbp35ZXyy3/fpvwqIRpR3VjoAx+QKajE4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fedev.571
  csrftest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  csuser:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          box:
            RATE_LIMIT_PER_SECOND: '1'
          processing_mode: REMEDIATION_ONLY
  deprovisiontest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(jVLFlaZNDOPTKIlHauA1664FOCWOTtD9ONnnE7/2+N+jLOXRMCxWFQ==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest
        POSTGRES_USER: ENC(kDOfu7K6e2kMk665KDIoeYwEr1S+BP5r6dA5jQARsMk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest
        MONGODB_TENANTDB_PWD: ENC(wRZWM+v169wqMn+8pmYg037OhS47zSls4DSCkfe8gNGN4fV20fC5FA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(0/5Bv9CyZs0Etk/YOj0Ay8rZHDJJHsSDahcWnEAcczw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(Z8JZ23uXBrXcO6QPSi80heT6NGirGn4UScQBN6latEesoQryj8nmMA==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest1
        POSTGRES_USER: ENC(sLmdJ66dSMesNGbCaDa9RFTjpiCtR3BMkOljVoKvK1I=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest1
        MONGODB_TENANTDB_PWD: ENC(/fUL9rIQIubDAHD6BmWQglCPX3Bl81Vawpc4GmAFPfqsx++E+FDF+A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(GyBSP2CLNZHsRlg7Qsgd5qZ+uM/f24ucFeFtkY3my3A=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest11:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(py1cj9IdXxnnNUfhpreR1GV6xVLukcQ1h0DezJEr8cWjv3AfUz2qPg==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest11
        POSTGRES_USER: ENC(TvZ3e7vlwOlmF3MWcn+2Em1ny3ooIKIZvuTas4pqt/s=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest11
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest11
        MONGODB_TENANTDB_PWD: ENC(8JZl9SPnK/7bIhG4xMI1K1ZFnlNx2oG3BVmxaCRhYAQ+bdX1UzD7EA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(RAXxWWK8Tfhq4i/TS9chsCt6b0L0A7ke5tTF/GfOp/s=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(lCcQsjn3hLGn17ImRKDjeewM+MEe/4hNbk6TpZTwULm4yZmS4Q4O+A==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest2
        POSTGRES_USER: ENC(H94xrzMNs47gX8EbBbaBI6aF29NXSKYpspeyuVEA/HI=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest2
        MONGODB_TENANTDB_PWD: ENC(2UJ+9z7phZK+4rm+PbZPS/2D7/l8sOwwmEt8et9+9rTpTRDiWw7SQg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(2lHcTlA9e58YJAG5I7xdW3a5pPLsG90iFOnOOrHSDPg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest3:
    config:
      v1:
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
    database:
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(V35mLWXJ/eftcZx8WQj8wsx6+lw1B45LF9jLFMDtYxeo0GgZj95I1w==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest3
        POSTGRES_USER: ENC(QWRW/tD2zJdXvS3xOWtMGl1mEhkyExgIvkLeKzW6diA=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest3
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest3
        MONGODB_TENANTDB_PWD: ENC(CD10Qi1PjGXr4QxXkV29dgZH+uD/YFsZaC9dq3iXR0XFXfgavyhuyw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(6p8gVBii01vcgziomUMl3miYkws51O5xZEXIORtbRLQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
  deprovisiontest6:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(4h3u63ZYcGOI4PHbgTLOZ3txX/KCGNCPcysm3//bbF1eZftjfh7bUg==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest6
        POSTGRES_USER: ENC(Qu6Rtq3LeKFl8mc+PMZtWVgGeBB9b88UTplPUO2fg1w=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest6
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest6
        MONGODB_TENANTDB_PWD: ENC(tAcFotUY5tKIZsLRRFHDXwnSHuCuAdFGvGvotd9V2FnhGJ+cEOY+sA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(dO5dHBZMFfIT95oxTijKQ0wDTf5N0fC3T24D83GdDCw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest7:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  deprovisiontest8:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(9JTQ2s/1iHy1vzLhFGPgwvaICA8XDrkAdOkBHktlxGekqGn3j8U8Zg==)
        POSTGRES_SCHEMA_NAME: cs_deprovisiontest8
        POSTGRES_USER: ENC(dXPKiV6wkeW8sPG2JI6ScJu+w8Kp8e1IHRxAlLjvLsQ=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_deprovisiontest8
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_deprovisiontest8
        MONGODB_TENANTDB_PWD: ENC(4TlW2yG8uydJ2IlR77dluqQVeun2IDbyd7R3l394qzCqpkbMAwpvPQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ANR32ziPmUPvYOfa4x+oOCdBqedEx2KCsQUVkt3qo+0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  deprovisiontest9:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  dgadetest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(u6/MrNlLaWgEOp6UL7jcSFFEE0ZBYxI2UFhvwzcT6CfzeAapJ5UFnQ==)
        POSTGRES_SCHEMA_NAME: cs_dgadetest
        POSTGRES_USER: ENC(Nym/x2+OwG6OnuUrC7GwYn2Whaf6dwNTr9Qncc5QoOI=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_dgadetest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_dgadetest
        MONGODB_TENANTDB_PWD: ENC(m9qtGLEWj10Xpg8j6SAMhkfzu+vgNNfcZNy0hxpxC5kTqxS6+R7Svg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(pIsvIvu6deuQjT5HsV3WBeMo511NkGK5eeXyNy1slQQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  dlpasync:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          async_asset_scan_enabled: 'True'
          dss-enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker-es7x: 3.13.41.5585-dev
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          google: 3.13.41.5585-dev
          queuecriteria:
            peak_hours_scan_disabled: 'True'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(bv1+VBcb0SXSWVxGV9dWfpYkmxTBHpyRESsw/oB3JkvzMGF+HuMZvA==)
        POSTGRES_SCHEMA_NAME: cs_dlpasync
        POSTGRES_USER: ENC(7pIzyhQwPEFtzE5uHZNGa/96ozix9M9dJtG6dCyml+Y=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_dlpasync
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_dlpasync
        MONGODB_TENANTDB_PWD: ENC(YXKKaSreMK1HdzIQ1Z+R+XVPvncTg/nsqoUZFnifT0NNbVBbKQZWzA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(apttM3odgcNp71zvHInXGbA79nlTurc8IWHMiTWp2k8=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: 3.13.41.5600-dev
      worker-es7x: 3.13.41.5600-dev
  dngo:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:45:31 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:45:31 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:45:31\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:45:31 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:45:31 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:45:31 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:45:31 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:45:31\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:45:31 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:45:31 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:45:31 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:45:31 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:45:31\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:45:31 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: dngo:analyze-ml, pid=116613 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:46:13 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"dngo.com\"\
          \n]\n20/02/28 19:46:13 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:46:13 WARN EsInputFormat: Cannot determine task id...\n20/02/28\
          \ 19:46:13 WARN EsInputFormat: Cannot determine task id...\n20/02/28 19:46:13\
          \ WARN EsInputFormat: Cannot determine task id...\n20/02/28 19:46:13 WARN\
          \ EsInputFormat: Cannot determine task id...\nINFO: writing 9 domains to\
          \ Mongo\nupsert_domain: paloaltonetworks.com\nupsert_domain: apertureatf.com\n\
          upsert_domain: gmail.com\nupsert_domain: apertureqa1.com\nupsert_domain:\
          \ probeapertureus.com\nupsert_domain: apertureqa.com\nupsert_domain: prismasaasdev.com\n\
          upsert_domain: apertureqa.onmicrosoft.com\nupsert_domain: apertureqa3.com\n\
          INFO: ------------------------------------------------\nINFO: user counts\
          \ by domain: service@dngo.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'probeapertureus.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@dngo.com'}\nINFO: {'domain': u'apertureqa.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@dngo.com'}\nINFO: {'domain':\
          \ u'prismasaasdev.com', 'user_count': 1, 'external': True, 'cs_user': 'service@dngo.com'}\n\
          INFO: {'domain': u'gmail.com', 'user_count': 5, 'external': True, 'cs_user':\
          \ 'service@dngo.com'}\nINFO: {'domain': u'apertureqa1.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@dngo.com'}\nINFO: {'domain':\
          \ u'paloaltonetworks.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@dngo.com'}\nINFO: {'domain': u'apertureqa3.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@dngo.com'}\nINFO: {'domain':\
          \ u'apertureatf.com', 'user_count': 2, 'external': True, 'cs_user': 'service@dngo.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@dngo.com'}\nINFO: #domains=9\n2020-02-28 19:46:14,163\
          \ MainThread spark-domain-count-dngo: INFO: user-counts-by-domain: time\
          \ to process people table=0.75\n2020-02-28 19:46:14,163 MainThread spark-domain-count-dngo:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.10\n\
          2020-02-28 19:46:14,163 MainThread spark-domain-count-dngo: INFO: user-counts-by-domain.interval=0.86\n"
        pid: null
        result: dngo:domain-count, pid=128000 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''dngo'', use_elasticsearch=False)

          2020-02-28 19:47:35,631 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dngo/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:47:35,635 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dngo/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:47:35,639 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dngo/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:47:35,639 MainThread spark-people-sort-dngo: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''dngo'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:47:36 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          20/02/28 19:47:36 WARN Utils: Service ''SparkUI'' could not bind on port
          4051. Attempting port 4052.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: dngo:people-sort, pid=15271 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(GUPuFBrgxRUc5aViTYFzbhf1lNk24QLrsU17rTz/gXdVHr1z5RnUAQ==)
        POSTGRES_SCHEMA_NAME: cs_dngo
        POSTGRES_USER: ENC(QZ7Ww/EBffiXYYVCV9TnvS3AqaM1EKuZhp+i1cBVnww=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_dngo
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_dngo
        MONGODB_TENANTDB_PWD: ENC(BDbqqsdsWxt11BWlUZA78EDezZH+3LV3ZfjOtpplSgMTz6neeSIf+Q==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(gz9cIL/LnhN4pkCFS7xm/lzTPUDZDLSk8E8kspTy+Fo=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  donald:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'False'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(9JYND2GdT3zqGxeTiRem7b0MY/CDUbG4CvXKm+WW/YLXvqjmwRRzlg==)
        POSTGRES_SCHEMA_NAME: cs_donald
        POSTGRES_USER: ENC(gsHnkngL4Q6hNEwOYLexD6bXi2vaHs5v5xiVtgyEFfM=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_donald
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_donald
        MONGODB_TENANTDB_PWD: ENC(se+T3t60Fk4dWQptnEQT9R+E4ltByCKz7BeY4vCq7dv8BR30hJbhLg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(rRl5WsEsmMbXTJcA/+iSNVIAvTakk5NDmlKkCb1Y6xE=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    deleted: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.74.2344
      fe: 4.1.144
  donald2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'False'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(M0wNOzQeOjq2vX/RwFYxx+UTZcAegficiUg94LBgvWinIF9OJnVxFg==)
        POSTGRES_SCHEMA_NAME: cs_donald2
        POSTGRES_USER: ENC(m5JQ9DsgXKh9mbYL24nQzqzffaZ7GCyib/xmLfBLijg=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_donald2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_donald2
        MONGODB_TENANTDB_PWD: ENC(Y3QD9VglZQ5w37UnPrGkptAsQ0HH/nlKEL9LjDeRTKDp94yJbkf24A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ZiTay89033HNSWfITqwRMg1hQJxCRezGmABMgZD9IRs=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.144
  dptest:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    deleted: '1'
  dss:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='dss')\n2020-02-28\
          \ 19:46:09,503 MainThread spark-people-sort-dss: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='dss')\n20/02/28 19:46:09 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:46:10 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:46:10\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:46:10 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:46:10 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:46:10 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:46:10 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:46:10\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\nTraceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: dss:analyze-ml, pid=128189 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:44:05 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:44:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:44:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:44:05 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:44:05 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:44:05 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:44:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:44:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:44:05 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:44:05 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:44:05 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:44:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:44:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:44:05 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: dss:domain-count, pid=94510 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''dss'', use_elasticsearch=False)

          2020-02-28 19:50:55,061 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dss/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:50:55,064 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dss/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:50:55,069 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/dss/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:50:55,070 MainThread spark-people-sort-dss: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''dss'', use_api=True, use_elasticsearch=False)

          20/02/28 19:50:55 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:50:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: ip-10-3-7-96.64143
        result: dss:people-sort, pid=64143 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(/a+fZ6ApnGayr7r3LM3bOvnQT6gwj25W0EX1Zjkd05o+gAhPOjf1pA==)
        POSTGRES_SCHEMA_NAME: cs_dss
        POSTGRES_USER: ENC(SusCizbRCFKl28T/NbwMleiGKZa7bba5BrNZYwoWn5o=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_dss
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_dss
        MONGODB_TENANTDB_PWD: ENC(uJ8oe2aoO5zY0nuptRkxg7QwzpTzc/ZWavZwar2qH2HYO/HYq47i2A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ULxPX75lyPIM0RkxmfwalLPlayNb+U3Cl7GMmvx6bY0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: '0.0.dss.529

        '
  es7gdhulipalla:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    versions:
      autolib: 1.97.2498
  es7v16test:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-2
        ES_QUERY_HOST: 10.3.0.95
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-2
      ES_QUERY_HOST: 10.3.0.95
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  es7v16testdss:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-2
        ES_QUERY_HOST: 10.3.0.95
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-2
      ES_QUERY_HOST: 10.3.0.95
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  esebastianwfm:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''esebastianwfm'')

          2020-02-28 19:44:51,111 MainThread spark-people-sort-esebastianwfm: INFO:
          Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''esebastianwfm'')

          20/02/28 19:44:51 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:44:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=esebastianwfm,build=1.0.32.b145,migrated=True,tenant=esebastianwfm,category=es_ip,subcategory=es_source_code:2395

          '
        pid: null
        result: esebastianwfm:analyze-ml, pid=106742 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.85191
        result: 'action: state=running'
        state: running
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''esebastianwfm'', use_elasticsearch=False)

          2020-02-28 19:48:59,065 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/esebastianwfm/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:48:59,069 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/esebastianwfm/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:48:59,072 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/esebastianwfm/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:48:59,073 MainThread spark-people-sort-esebastianwfm: INFO:
          Namespace(api_endpoint=''http://internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''esebastianwfm'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:48:59 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:49:00 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:49:00 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:49:00 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:49:00 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com:8080/database/write

          '
        pid: null
        result: esebastianwfm:people-sort, pid=36424 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          ? ''
          : null
          google_whitelist_emails: qa@apertureqa.com
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wfm:
          ? ''
          : null
          enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(mAa0pU6jkahYYHkzu7697q5UAX3e3ryh0evFxejXWRYjWNRfEshX8A==)
        POSTGRES_SCHEMA_NAME: cs_esebastianwfm
        POSTGRES_USER: ENC(kZeQuDnqeCefX4kYa7oA2PFlaUKJZB7KfEM75HD72fY=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_esebastianwfm
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_esebastianwfm
        MONGODB_TENANTDB_PWD: ENC(oZvlMZTccLj4B0txzpZgZh/KZcr1O663MujHQJV+9QatWF9uhJR80A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(2XMouqTFIqW6mfzHKalHMj4INc1k6coBeMR/0ItQaKg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: null
  fbwp:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''fbwp'')

          2020-02-28 19:42:36,945 MainThread spark-people-sort-fbwp: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''fbwp'')

          20/02/28 19:42:37 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4051. Attempting port 4052.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4052. Attempting port 4053.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4053. Attempting port 4054.

          20/02/28 19:42:38 WARN Utils: Service ''SparkUI'' could not bind on port
          4054. Attempting port 4055.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=fbwp,build=1.0.32.b145,migrated=True,tenant=fbwp,category=es_ip,subcategory=es_source_code:2

          '
        pid: ip-10-3-7-96.85463
        result: fbwp:analyze-ml, pid=72001 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:49:30 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"fbwp.com\"\
          , \n    \"apertureqa.com\"\n]\n20/02/28 19:49:31 WARN EsInputFormat: Cannot\
          \ determine task id...\n20/02/28 19:49:31 WARN EsInputFormat: Cannot determine\
          \ task id...\nINFO: writing 11 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@fbwp.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'yahoo.co.in', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@fbwp.com'}\nINFO: {'domain': u'yahoo.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@fbwp.com'}\nINFO: {'domain': u'paloaltonetworks.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@fbwp.com'}\nINFO:\
          \ {'domain': u'apertureqa3.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@fbwp.com'}\nINFO: {'domain': u'paloaltonetwors.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@fbwp.com'}\nINFO:\
          \ {'domain': u'gmail.com', 'user_count': 4, 'external': True, 'cs_user':\
          \ 'service@fbwp.com'}\nINFO: {'domain': u'apertureqa3.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@fbwp.com'}\nINFO: {'domain':\
          \ u'facebook.com', 'user_count': 1, 'external': True, 'cs_user': 'service@fbwp.com'}\n\
          INFO: {'domain': u'prismasaasqa.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@fbwp.com'}\nINFO: {'domain': u'apertureqa1.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@fbwp.com'}\nINFO: {'domain':\
          \ u'apertureqa.com', 'user_count': 6, 'external': False, 'cs_user': 'service@fbwp.com'}\n\
          INFO: #domains=11\n2020-02-28 19:49:32,235 MainThread spark-domain-count-fbwp:\
          \ INFO: user-counts-by-domain: time to process people table=0.69\n2020-02-28\
          \ 19:49:32,236 MainThread spark-domain-count-fbwp: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.00\n2020-02-28 19:49:32,236 MainThread\
          \ spark-domain-count-fbwp: INFO: user-counts-by-domain.interval=0.70\n"
        pid: null
        result: fbwp:domain-count, pid=42896 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.82389
        result: 'action: state=running'
        state: running
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: v4
        wfm:
          enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
          workplace:
            group_database_page_size: '2'
            group_feed_fetch_enabled: 'true'
            quota_feedback_pausing_percentage_to_pause_at: '800'
            refresh_user_cache: '300'
            user_database_page_size: '2'
            user_database_type: redis
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(uyAROpfXfL1yYek1Bz0gHsVPFkrcWwsm149DZ3fjzjDBgijra6+f5w==)
        POSTGRES_SCHEMA_NAME: cs_fbwp
        POSTGRES_USER: ENC(lAwI1gL1B/zdSOiggzc7jLit4VBNlyUEin0/MHQCLPw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_fbwp
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_fbwp
        MONGODB_TENANTDB_PWD: ENC(9AqlPxUJmzzn9T3eqwBzNe+Bs04ZjurYmuD3/yraKYdDb+JY/eEXxQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(gqkbzMet5Q8pcNbZ1BUvUW9OaQ8ReX3UfO1NvKA9RSE=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.70.2151
      fe: 0.0.sysui.159
      worker: 3.13.41.4682-dev
  fomigrationtest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'false'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'false'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(Yl6DbLvBZFw8ZVTsQDMgd+p+6GiNWM8mNz5JnyQuxCAeFkjugrLTpg==)
        POSTGRES_SCHEMA_NAME: cs_fomigrationtest
        POSTGRES_USER: ENC(YDOJr2vYMdaN0Ri8+BdN48qqzNsC+evKgkZrlK6uFEk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_fomigrationtest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_fomigrationtest
        MONGODB_TENANTDB_PWD: ENC(yZ1tJ54XJB0Ha0n2TdOKHSCsFl6rRNlYNUgeyyHt/B3ju4BE0fbFSw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(9V4Lf3E5O5a8QWbFhKeE6yeW4+VBUWh7tChGbWbX5EU=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.dev.156
  gdhulipalla:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(q0W8vkGqvHihRCAhMj75URu4ha3MpaCvqi91ph9w2puM/CViDbJ1dw==)
        POSTGRES_SCHEMA_NAME: cs_gdhulipalla
        POSTGRES_USER: ENC(hR44mwhnlURkeiwM2vinBJi/4NEpF0u0L41/+sNsSTE=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_gdhulipalla
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_gdhulipalla
        MONGODB_TENANTDB_PWD: ENC(zJCsv3G8uwt+u9lm05teY3EaYRr0AgapSyLstIOJdOCDCLcq6FMslg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(vctROZ8rACemhl70AX8o3CRB0E61i4hgJQfpxUnajAQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.es7x.2020.07.20.67
      worker: 3.13.41.4997-dev
      worker-es7x: 3.13.41.4478-dev
  gdhulipalla1:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''gdhulipalla1'')

          2020-02-28 19:45:35,779 MainThread spark-people-sort-gdhulipalla1: INFO:
          Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''gdhulipalla1'')

          20/02/28 19:45:36 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:45:37 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=gdhulipalla1,build=1.0.32.b145,migrated=True,tenant=gdhulipalla1,category=es_ip,subcategory=es_source_code:20

          '
        pid: null
        result: gdhulipalla1:analyze-ml, pid=119091 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:49:02 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"prismatechdocs.com\"\
          , \n    \"prismasaasdev.com\"\n]\n20/02/28 19:49:02 WARN EsInputFormat:\
          \ Cannot determine task id...\n20/02/28 19:49:02 WARN EsInputFormat: Cannot\
          \ determine task id...\nINFO: writing 19 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@gdhulipalla1.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'yahoo.com', 'user_count': 3, 'external': True, 'cs_user':\
          \ 'service@gdhulipalla1.com'}\nINFO: {'domain': u'yahoo.co.in', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain':\
          \ u'boxdevedition.com', 'user_count': 30, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'apertureqa3.onmicrosoft.com', 'user_count': 2, 'external':\
          \ True, 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain': u'gmail.com',\
          \ 'user_count': 11, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'paloaltonetworks.com', 'user_count': 8, 'external': True,\
          \ 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain': u'paloaltonetwors.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'cirrosecure.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain': u'aperturead1.com',\
          \ 'user_count': 3, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'apertureqa5.onmicrosoft.com', 'user_count': 11, 'external':\
          \ True, 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain': u'cirrotester.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain': u'aperturesync.onmicrosoft.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'box.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@gdhulipalla1.com'}\nINFO: {'domain': u'xoriant.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain':\
          \ u'facebook.com', 'user_count': 1, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: {'domain': u'apertureqa.com', 'user_count': 7, 'external': True, 'cs_user':\
          \ 'service@gdhulipalla1.com'}\nINFO: {'domain': u'prismasaasdev.com', 'user_count':\
          \ 7, 'external': False, 'cs_user': 'service@gdhulipalla1.com'}\nINFO: {'domain':\
          \ u'apertureqa3.com', 'user_count': 2, 'external': True, 'cs_user': 'service@gdhulipalla1.com'}\n\
          INFO: #domains=19\n2020-02-28 19:49:03,124 MainThread spark-domain-count-gdhulipalla1:\
          \ INFO: user-counts-by-domain: time to process people table=0.69\n2020-02-28\
          \ 19:49:03,124 MainThread spark-domain-count-gdhulipalla1: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.01\n2020-02-28 19:49:03,124 MainThread\
          \ spark-domain-count-gdhulipalla1: INFO: user-counts-by-domain.interval=0.70\n"
        pid: null
        result: gdhulipalla1:domain-count, pid=29538 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:51:05 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:51:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:51:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:51:05 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:51:05 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:51:05 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:51:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:51:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:51:05 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:51:05 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:51:05 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:51:05 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:51:05\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:51:05 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.68347
        result: gdhulipalla1:people-sort, pid=68347 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          enable_syslog_enhancement_true_type: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          health_check:
            ? ''
            : null
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'True'
        versions:
          ? ''
          : null
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          ? ''
          : null
          github:
            support_dlp: 'false'
          google:
            ? ''
            : null
            max_api_calls_per_unit: '9'
            process_shared_drives: 'true'
            queue_scan_restricted_hours_utc: 16-17
            shared_drive_refresh_lock_in_minutes: '5'
          office365:
            owner_update: 'false'
            remediation_priority: 'true'
          sharepoint_site_refresh_exposure_cycle_in_hours: '0'
          workplace:
            ? ''
            : null
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(V3jG2o0mz15lzRzx2kIx99Fm7bMUizF0eS6cKxGSaXa1oxyCCj3w1g==)
        POSTGRES_SCHEMA_NAME: cs_gdhulipalla1
        POSTGRES_USER: ENC(Z/iDp3oY/mYCqqlpse4tf9M1FVHHTWyxpluRy/sWdM0=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_gdhulipalla1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_gdhulipalla1
        MONGODB_TENANTDB_PWD: ENC(5r16CwnoAHtcqtVZ/eIJdIr1UQHErKhO/kl5vvSz3cTN4ChK6vEQ/g==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ZbVOTyfFkdAYgtC26fCJANslLFVT/qKdgVh7HnfxnVc=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      ? ''
      : null
      autolib: 1.74-dev.2646
      fe: 4.1.292
  gdhulipalla2:
    analytics:
      $disabled: 'true'
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.133.2
      fe: 4.1.344-es7
  ghautomation:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          async_enabled: 'false'
          dss-enabled: 'true'
          dss_version: v2
          snippets_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            enabled: 'true'
          gamma:
            enabled: 'true'
          pan_sso:
            enabled: 'False'
          slackstandard:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(+TW8zWYaBie4O/rZCKJGyujQ7n5emK0g1bLkHvkpiEucr+LnmMx3aA==)
        POSTGRES_SCHEMA_NAME: cs_ghautomation
        POSTGRES_USER: ENC(XnmXVu1yAPcaMwpKLyfT8dRMuux9rwwloF7wina05kY=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautomation
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautomation
        MONGODB_TENANTDB_PWD: ENC(63alvNfoL1CK28TFQrUHe20LVnAGnJa9P0KTxSSyxz30vGAdFhiL0A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(UpqtavHEDd5MkotHkWBifqgU9wWQgYxxks7NN43OJEs=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghautomation2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
          dss_version: v2
          snippets_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            enabled: 'true'
          gamma:
            enabled: 'true'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(hfMnA7cegqajlphSy3LzQVjZOuDZkE8CZvOSekS5zU9IwIzo2W+k0g==)
        POSTGRES_SCHEMA_NAME: cs_ghautomation2
        POSTGRES_USER: ENC(SQJkxRnbHdsnSqfVK6PksJfpG+nlgZ/bgVDS7iUxKSs=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautomation2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautomation2
        MONGODB_TENANTDB_PWD: ENC(CvRvMiBAjO+wO3ZTCD5MJhTCQF/SQzvNWuGLV6gtHhnvf1uk04sDhw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(vaPNZ8ds7qx03lxiAn+Z9S8hsRCwTgpimyxCKbec0Mk=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghautomation3:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
          dss_version: v2
          snippets_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            enabled: 'true'
          gamma:
            enabled: 'true'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(RozmXZyvPpSwYiho3GEViMqvPy/r3KETCsNbbknfWqnkAFwvJ5LJ1A==)
        POSTGRES_SCHEMA_NAME: cs_ghautomation3
        POSTGRES_USER: ENC(PgnQrxbQ070ivYBtl4VII+Vnw8GjPoO4LiclxF06uEE=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautomation3
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautomation3
        MONGODB_TENANTDB_PWD: ENC(BCcu6y84MmeWUE0hP3YKvuJfa3pFK9vOhD3bemczZJkTMnsa9K30yA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(wjhyPZ5tyWBOg70Ba+XWMrAABhUO8H6QTxs84ydJNEo=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghautotest1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'true'
          dss_version: v2
          snippets_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            enabled: 'true'
          gamma:
            enabled: 'true'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(KAyKOsJJOK3jDeI38q7Eo1S2vwRodYFeRvubDYkHWzTe4fXPuRSmVA==)
        POSTGRES_SCHEMA_NAME: cs_ghautotest1
        POSTGRES_USER: ENC(1I2pxb0RjEqe7mo2jE1HR8zt3PuIW3l7EqYJWipLat0=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautotest1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautotest1
        MONGODB_TENANTDB_PWD: ENC(aj6v/Vw3FJsieLIQnzSWAsXxfpV4CzBuOMV4yBghqX2npncStbSEwg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(EViRaHkQC8AeHXukx2KO4PDHS9yWpetE8gAbVTFqA6o=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghautotest3:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'true'
          dss_version: v2
          snippets_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            enabled: 'true'
          gamma:
            enabled: 'true'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(4eRm+7AA8rkuHlt68kNS7xg5QiJC/iRYSavDDGn2mUBW3G8Pp5P/RA==)
        POSTGRES_SCHEMA_NAME: cs_ghautotest3
        POSTGRES_USER: ENC(wnOa8nLD5JXRIOj+w/NMLj6jAB2Huqzrs4+AHIIMkpw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautotest3
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautotest3
        MONGODB_TENANTDB_PWD: ENC(JALK8nEPi1vPHNkU8qStlsc1lFnRgbArizk0nscSg6VP2/a8Yrhe5w==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(yYDvRWVqlLHNaTXl66+6ice3WU5objfD+J8iwTpVWm4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghautotest4:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(fiSD73p0LK6zvsjmHhL3KgZ/lPNieQw6YBC5NzJOWbbLRSY419q0JQ==)
        POSTGRES_SCHEMA_NAME: cs_ghautotest4
        POSTGRES_USER: ENC(8CPFBmdVLdjQhyQT+lYbnT0Do/nHep5iOfvCtrO2rvQ=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghautotest4
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghautotest4
        MONGODB_TENANTDB_PWD: ENC(m0fnjnKHmsI/IgtJWLMT4xGzO/LWr06dyGQV6bWfOjWaLftjPWqGtw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(WlKN6usJcFwl7FuOfr3KkLCniBBzc0j9rzPYHzb1iog=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghstg2automation:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.195.1
  ghstg2automation2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'false'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ghtest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'false'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(zLMQkwssF0PVfbuhFprCagVII89V6JMBoJ/zQ1lk3UvXuEyJE5OyQQ==)
        POSTGRES_SCHEMA_NAME: cs_ghtest
        POSTGRES_USER: ENC(pZx4H+bY0QjhF+2AbiXFA84b4Jod/ZEn1cNOWZaHqKQ=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ghtest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ghtest
        MONGODB_TENANTDB_PWD: ENC(NBtVJDR2lYtm4No6KzomF04dos+9EbiqUqyUdaU4qhzIstSpmksL6A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(taluU6VJYHkHscRKHxfYCfTE95OZF5wS9q2LYVACib0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      ? ''
      : null
      fe: 0.0.ghslack.331
  greystg2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'false'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        apps:
          gdrivev2:
            backward_scan: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          async_enabled: 'false'
          dss-enabled: 'true'
        fe:
          bitbucket:
            enabled: 'true'
          data_violations:
            enabled: 'true'
          debug_mode: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
            violations: 'true'
          gdrivev2:
            ? ''
            : null
            enabled: 'true'
          github_marketplace:
            enabled: 'True'
          jira:
            enabled: 'true'
          notifications:
            ? ''
            : null
            app: slackstandard
          pan_sso:
            enabled: 'False'
          slackenterprise:
            enabled: 'true'
          slackenterprise_bot:
            enabled: 'true'
          slackstandard:
            enabled: 'true'
          zendesk:
            ? ''
            : null
            enabled: 'true'
          zoom:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wfm:
          malware_analysis_status_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(2Q5/APZA/3uVYTofsIoM4o8GOy8ySOh2sbb2EDQIl5gbIaGO8vCQ0Q==)
        POSTGRES_SCHEMA_NAME: cs_greystg2
        POSTGRES_USER: ENC(zvjqAa6m1LGZCULv6cyVCOWcU6iXfTrUZY8snDLUDuk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_greystg2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_greystg2
        MONGODB_TENANTDB_PWD: ENC(MEDDQex2NqMVQNO1MgCWWLAs47kcAGDshPms3oY3W8WTQxF4x4We6g==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(Z4ZyrLVCwOJHu4YTEiSbB6B3Yy6CWRJI19YdxLpVvaQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.579-es7
  guilleva:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(pDEWWKWnETavlKI0qXtodl9k4sg8GHy1OsJ11EK8ibYpd5Vxh+WGjg==)
        POSTGRES_SCHEMA_NAME: cs_guilleva
        POSTGRES_USER: ENC(0KsfHN0MaNVOSboy6oYS+DIhvjGFG478MXLlUG83/Rw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_guilleva
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_guilleva
        MONGODB_TENANTDB_PWD: ENC(lzCQsUNN5CjyS01ttNMwcRMgyCYh+ifDkJMnftU9woEKV08qavyvRw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(YJIbOEuMMInZhdDAKOEgsuWHZW3JkT5P5TGzCHnLsj4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  gvargas:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''gvargas'')

          2020-02-28 19:50:21,068 MainThread spark-people-sort-gvargas: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''gvargas'')

          20/02/28 19:50:21 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:50:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=gvargas,build=1.0.32.b145,migrated=True,tenant=gvargas,category=es_ip,subcategory=es_source_code:166

          '
        pid: ip-10-3-7-96.54668
        result: gvargas:analyze-ml, pid=54668 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: 'upsert_domain: competitor-eval.iam.gserviceaccount.com

          upsert_domain: cirrosecure.com

          upsert_domain: dataflow-service-producer-prod.iam.gserviceaccount.com

          upsert_domain: apertureqa3.com

          upsert_domain: boxdevedition.com

          upsert_domain: cirrotester.com

          upsert_domain: uttam-test-project.iam.gserviceaccount.com

          upsert_domain: aperture-gcp-storage.iam.gserviceaccount.com

          upsert_domain: cloudservices.gserviceaccount.com

          upsert_domain: developer.gserviceaccount.com

          upsert_domain: gmail.com

          upsert_domain: apertureqa1.com

          upsert_domain: container-engine-robot.iam.gserviceaccount.com

          upsert_domain: containerregistry.iam.gserviceaccount.com

          upsert_domain: nifty-time-170522.iam.gserviceaccount.com

          upsert_domain: aperturesync.onmicrosoft.com

          upsert_domain: wuyou-test-217418.iam.gserviceaccount.com

          upsert_domain: even-equinox-188119.iam.gserviceaccount.com

          INFO: ------------------------------------------------

          INFO: user counts by domain: service@gvargas.com

          INFO: ------------------------------------------------

          INFO: {''domain'': u''paloaltonetworks.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''cirrotester.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''gmail.com'', ''user_count'': 8, ''external'': True,
          ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''aperture-gcp-storage.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''cirrosecure.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''boxdevedition.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''containerregistry.iam.gserviceaccount.com'', ''user_count'':
          5, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''cloudservices.gserviceaccount.com'', ''user_count'':
          11, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''nifty-time-170522.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''dataflow-service-producer-prod.iam.gserviceaccount.com'',
          ''user_count'': 2, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''container-engine-robot.iam.gserviceaccount.com'',
          ''user_count'': 5, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''wuyou-test-217418.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''compute-system.iam.gserviceaccount.com'', ''user_count'':
          11, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''competitor-eval.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''jtest1-gcp.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''aperturesync.onmicrosoft.com'', ''user_count'': 1,
          ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''box.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''even-equinox-188119.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''uttam-test-project.iam.gserviceaccount.com'', ''user_count'':
          2, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''developer.gserviceaccount.com'', ''user_count'': 11,
          ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''apertureqa1.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''apertureqa.com'', ''user_count'': 8, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''dlp-api.iam.gserviceaccount.com'', ''user_count'':
          2, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''cloud-redis.iam.gserviceaccount.com'', ''user_count'':
          1, ''external'': True, ''cs_user'': ''service@gvargas.com''}

          INFO: {''domain'': u''apertureqa3.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@gvargas.com''}

          INFO: #domains=25

          2020-02-28 19:46:20,730 MainThread spark-domain-count-gvargas: INFO: user-counts-by-domain:
          time to process people table=0.68

          2020-02-28 19:46:20,730 MainThread spark-domain-count-gvargas: INFO: user-counts-by-domain:
          time to write to mongo/elasticsearch=0.29

          2020-02-28 19:46:20,730 MainThread spark-domain-count-gvargas: INFO: user-counts-by-domain.interval=0.97

          '
        pid: null
        result: gvargas:domain-count, pid=130538 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:51:06 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:51:06 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:51:06\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:51:06 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:51:06 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:51:06 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:51:06 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:51:06\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:51:06 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:51:06 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:51:06 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:51:06 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:51:06\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:51:06 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.68761
        result: gvargas:people-sort, pid=68761 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_saas_visibility:
            ? ''
            : null
            enable:
              ? ''
              : null
              'true': null
          notify_issues_by_email:
            delayed_job: 'true'
            download: 'true'
            license: 'true'
          pan_sso:
            enabled: 'true'
          redis:
            ? ''
            : null
            global_setting_cache: 'true'
            global_setting_cache_expires_in: '12'
          workplace_app_id: '352896818721127'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(G4g2G9tisUA7qxNuJ0LxqLbT/dSXBBmVuAw+6Ames9C9S2A+pi0WzQ==)
        POSTGRES_SCHEMA_NAME: cs_gvargas
        POSTGRES_USER: ENC(z2eH/q4DiBsXPBiDlHg3TSARFdgUHBmHwTHLxw82BSk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_gvargas
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_gvargas
        MONGODB_TENANTDB_PWD: ENC(678FQbMwuaKVTeayCRQlsU9S/BWHL8wAlIeNvCfOGkvMiDaKrqU64A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(YU7+7WjTonQvl50hSgngan2bWtWxFXBW6FUoUVv6Zuo=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.48.1951
      fe: 0.0.dev.833
      worker: 3.13.52.d4
  hotfix:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  jcenter:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''jcenter'')

          2020-02-28 19:44:53,011 MainThread spark-people-sort-jcenter: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''jcenter'')

          20/02/28 19:44:53 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:44:54 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jcenter,build=1.0.32.b145,migrated=True,tenant=jcenter,category=es_ip,subcategory=es_source_code:4394

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jcenter,build=1.0.32.b145,migrated=True,tenant=jcenter,category=es_finance,subcategory=es_pci_finac:20

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jcenter,build=1.0.32.b145,migrated=True,tenant=jcenter,category=es_finance,subcategory=es_pci_perfi:15

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jcenter,build=1.0.32.b145,migrated=True,tenant=jcenter,category=es_legal,subcategory=es_standard_business_agreements:111

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jcenter,build=1.0.32.b145,migrated=True,tenant=jcenter,category=es_legal,subcategory=es_bankruptcy_filings:7

          '
        pid: null
        result: jcenter:analyze-ml, pid=107293 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\
          \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\
          \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\t\
          at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\
          \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1890)\n\tat\
          \ org.apache.spark.SparkContext.runJob(SparkContext.scala:1903)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1916)\n\
          \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1930)\n\tat\
          \ org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912)\n\tat\
          \ org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:911)\n\
          \tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\
          \tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest:\
          \ null\nc2NhbjsxOzgyMjMyNDU5Mjk6VU5lU2xUWW5SRXFiUFdUOXBhem9WZzsxO3RvdGFsX2hpdHM6MjAwOTUyOw==\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:427)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:385)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:375)\n\
          \tat org.elasticsearch.hadoop.rest.RestClient.scroll(RestClient.java:445)\n\
          \tat org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:436)\n\
          \tat org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:86)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.next(EsInputFormat.java:298)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.nextKeyValue(EsInputFormat.java:232)\n\
          \tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182)\n\
          \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)\n\
          \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\t\
          at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat\
          \ org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:120)\n\
          \tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:112)\n\
          \tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)\n\
          \tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)\n\
          \tat org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)\n\
          \tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1877)\n\
          \tat org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)\n\
          \n\n"
        pid: null
        result: jcenter:domain-count, pid=130689 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='jcenter', use_elasticsearch=False)\n\
          2020-02-28 19:47:07,400 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/jcenter/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:47:07,404 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/jcenter/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:47:07,407 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/jcenter/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:47:07,407 MainThread spark-people-sort-jcenter:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='jcenter', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:47:07 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\n\r[Stage 0:>                                     \
          \                   (0 + 36) / 36]\r[Stage 0:>                         \
          \                               (0 + 36) / 36]\r[Stage 0:>             \
          \                                           (0 + 36) / 36]\r[Stage 0:> \
          \                                                       (0 + 36) / 36]\r\
          [Stage 0:>                                                        (0 + 36)\
          \ / 36]"
        pid: ip-10-3-7-96.11572
        result: 'action: state=running'
        state: running
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        app_health_check_enabled: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enable: 'true'
          assets_search:
            async_filters: 'true'
            debug: 'true'
            fast_mode: 'true'
          async_download:
            ? ''
            : null
            custom_resources: Person,GdprReport
            enabled: 'true'
          combined_visibility:
            enabled: 'true'
          debug_mode: 'true'
          health_check:
            ? ''
            : null
            enabled: 'true'
          multi_factor_authentication:
            enable: 'true'
          saml_proxy:
            enabled: 'true '
          saml_proxy_redesign:
            enabled: 'true'
          service_discovery:
            ? ''
            : null
            custom_tags: dashboard-service:es7x/data-pattern:es7x/remediation:es7x/data-policy-violation:es7x
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'True'
        skip_rta_processing: 'False'
        slurper_enabled: 'false'
        versions:
          ? ''
          : null
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(tFgdTh8hGEf8UN0EK48eIAYUoM73Xrsrj8mC813oBuNMDK6kptXOFw==)
        POSTGRES_SCHEMA_NAME: cs_jcenter
        POSTGRES_USER: ENC(YzqPP023Pnz+3n0xiU5jaPewiYFgPFiMVmSiFrarUBA=)
      samlproxy:
        cockroach:
          ? ''
          : null
          HOST: 10.3.4.245
          PORT: '26257'
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_jcenter
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_jcenter
        MONGODB_TENANTDB_PWD: ENC(B+JsNZreH6GDeZmC57WSNSHFXRIsDfCPFKGmu8YP7/Qsb22pRr8vWg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(oKEM5T/AXQqlihGf9x1oJMA+YqOw3lpxSjjIlTf+wK4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9300'
      TRANSPORT_PORT: '9200'
    versions:
      fe: 4.1.426-es7
      fe-es7x: 4.1.426-es7
  jgundayao2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
          sspm:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fedev.551
  josfernandeznodss:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          msteams:
            enabled: 'true'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        notifications:
          use_sender_from_setings: 'True'
        skip_rta_processing: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          github:
            support_dlp: 'true'
          google:
            process_only_primary_events: 'true'
            process_shared_drives: 'true'
          o365:
            email_from_proxy: 'true'
            enable_active_sites_scheduling: 'false'
            external_email_ends_with: '@aperturesync.com'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(9neCL7kvGSpZmWfs3z+DiUwCIXuVrX0UEGWav7MhysZesALJd5ULtQ==)
        POSTGRES_SCHEMA_NAME: cs_josfernandeznodss
        POSTGRES_USER: ENC(hedqzfwxw6yLasXMgX5zXoBqENPx+dT6HzXZHg6qPRs=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_josfernandeznodss
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_josfernandeznodss
        MONGODB_TENANTDB_PWD: ENC(sBL9MltgTtMwWNz4Rjhy+YrL83DnsMWNvP3SV68dhz37BsIyTzdr4w==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(C32XQlmD63krcA3WjaWPQYGQ++i+fUieQLJ3v6XGvEk=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_metadata_from_dp_results: 'TRUE'
    fetch_snippets_without_subscription: 'True'
    versions:
      fe: 0.0.iadp.310
      worker:
        office365: 3.13.41.5483-dev
        workplace: 3.13.41.5550-dev
  josfernandeztenant:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(AqWusuaDcSS5EFRo3u9EyW2nYTP8pMt1o+H2/wQZQnhXQU1zo8QeSg==)
        POSTGRES_SCHEMA_NAME: cs_josfernandeztenant
        POSTGRES_USER: ENC(40HAge5CcCLWWIY6gnR6WLIECtiOonChafjFNkql8sw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_josfernandeztenant
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_josfernandeztenant
        MONGODB_TENANTDB_PWD: ENC(BJhYx3d/m/SRDeuPyBa4wURz/NBD+jSGS/2gr6ugCl7Gwx9/LfThOg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(KT2HKDm5vFDl5z4yM+LANuqqwUIYF7+ycM1ip5jZNIM=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  josfernandeztenant2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  jxue:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''jxue'')

          2020-02-28 19:49:33,885 MainThread spark-people-sort-jxue: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''jxue'')

          20/02/28 19:49:34 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:49:34 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:49:34 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:49:34 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:49:35 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=jxue,build=1.0.32.b145,migrated=True,tenant=jxue,category=es_ip,subcategory=es_source_code:3

          '
        pid: null
        result: jxue:analyze-ml, pid=44878 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:45:42 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"jxue.com\"\
          , \n    \"paloaltonetworks.com\"\n]\n20/02/28 19:45:42 WARN EsInputFormat:\
          \ Cannot determine task id...\n20/02/28 19:45:42 WARN EsInputFormat: Cannot\
          \ determine task id...\nINFO: writing 10 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@jxue.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'citrix.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@jxue.com'}\nINFO: {'domain': u'paloaltonetworks.com', 'user_count':\
          \ 6, 'external': False, 'cs_user': 'service@jxue.com'}\nINFO: {'domain':\
          \ u'apertureperf.com', 'user_count': 1, 'external': True, 'cs_user': 'service@jxue.com'}\n\
          INFO: {'domain': u'slack-corp.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@jxue.com'}\nINFO: {'domain': u'gmail.com', 'user_count': 2, 'external':\
          \ True, 'cs_user': 'service@jxue.com'}\nINFO: {'domain': u'apertureqa3.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@jxue.com'}\nINFO:\
          \ {'domain': u'apertureqa1.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@jxue.com'}\nINFO: {'domain': u'sharefile.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@jxue.com'}\nINFO: {'domain':\
          \ u'apertureatf.com', 'user_count': 4, 'external': True, 'cs_user': 'service@jxue.com'}\n\
          INFO: {'domain': u'alvisofin.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@jxue.com'}\nINFO: #domains=10\n2020-02-28 19:45:42,904 MainThread\
          \ spark-domain-count-jxue: INFO: user-counts-by-domain: time to process\
          \ people table=0.71\n2020-02-28 19:45:42,904 MainThread spark-domain-count-jxue:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:45:42,904 MainThread spark-domain-count-jxue: INFO: user-counts-by-domain.interval=0.71\n"
        pid: null
        result: jxue:domain-count, pid=119750 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''jxue'', use_elasticsearch=False)

          2020-02-28 19:49:01,132 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/jxue/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:49:01,137 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/jxue/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:49:01,142 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/jxue/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:49:01,143 MainThread spark-people-sort-jxue: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''jxue'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:49:01 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:49:02 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          2020-02-28 19:49:33,885 spark-people-sort-jxue INFO Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''jxue'')

          '
        pid: null
        result: jxue:people-sort, pid=37570 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        REMEDIATION_API_CALL_LIMIT: '30000'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'false'
          saml_proxy:
            enabled: enabled
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(BzAJoGndVWe1Pupfhbvd5MhGJR0fhnctEgRzt/7VG6LvQcviZb0r/w==)
        POSTGRES_SCHEMA_NAME: cs_jxue
        POSTGRES_USER: ENC(4FbiUVI9GimbTqKIo5xIIMiBEs+h+Tr27v0rLDMI/zI=)
      samlproxy:
        cockroach:
          HOST: 10.3.4.245
          PORT: '26257'
          SSL: 'true'
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_jxue
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_jxue
        MONGODB_TENANTDB_PWD: ENC(z80f0GbUDKQ50cgQoiIO81/VQ2p9PtPtSK76oDbQphC5pofRBiq6qg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(BBR2mL7hHMklY5Iw2/psbbflXbOqXwo8wb2lUqINg+w=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    samlproxy:
      hqvpc:
        DATACENTER: test
        REGION: us-east-1
    versions:
      autolib: 1.48.1951
      fe: 4.1.120
      worker: 3.13.41.4146-dev
  kanumothu1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(MiGU2uimPMJueCctwcHcvRCKyYJDVs3JyJzEkRs1hj/RBrfgMijsgw==)
        POSTGRES_SCHEMA_NAME: cs_kanumothu1
        POSTGRES_USER: ENC(WaSBkG71+IdfjenOyVskUBmwetbUCYEy/gKGYUIyDDs=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_kanumothu1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_kanumothu1
        MONGODB_TENANTDB_PWD: ENC(672VSvbq7AC4JgpoOWZlYu8c2TYf5XQg3DPLiDU6W5PQ+hI2TK3u5g==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(X3roOp9YRJ7UfkOWxgdz07fo99A+UfRuW33FZoTVlnQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  kkren:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          bitbucket:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          google_whitelist_emails: admin@prismasaasdev.com
          jira:
            enabled: 'true'
          msteams:
            enabled: 'true'
          pan_sso:
            enabled: 'false'
          sspm:
            enabled: 'true'
          zoom:
            enabled: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      ? ''
      : null
      fe: 0.0.uob.707
  kkrenes7:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  lizzy:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.70900
        result: 'action: state=running'
        state: running
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:48:08 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"lizzy.com\"\
          \n]\n20/02/28 19:48:08 WARN EsInputFormat: Cannot determine task id...\n\
          INFO: writing 22 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@lizzy.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'alvisofin.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@lizzy.com'}\nINFO: {'domain': u'paloaltonetworks.com', 'user_count':\
          \ 14, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain':\
          \ u'box.com', 'user_count': 1, 'external': True, 'cs_user': 'service@lizzy.com'}\n\
          INFO: {'domain': u'apertureqa6.onmicrosoft.com', 'user_count': 2, 'external':\
          \ True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain': u'apertureqa.com',\
          \ 'user_count': 3, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO:\
          \ {'domain': u'apertureqa3.com', 'user_count': 3, 'external': True, 'cs_user':\
          \ 'service@lizzy.com'}\nINFO: {'domain': u'skyparity.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain':\
          \ u'cirrosecure.com', 'user_count': 2, 'external': True, 'cs_user': 'service@lizzy.com'}\n\
          INFO: {'domain': u'probeapertureus.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@lizzy.com'}\nINFO: {'domain': u'prismasaasdev.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO:\
          \ {'domain': u'boxdevedition.com', 'user_count': 3, 'external': True, 'cs_user':\
          \ 'service@lizzy.com'}\nINFO: {'domain': u'cirrotester.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain':\
          \ u'broadcom.com', 'user_count': 1, 'external': True, 'cs_user': 'service@lizzy.com'}\n\
          INFO: {'domain': u'xoriant.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@lizzy.com'}\nINFO: {'domain': u'gmail.com', 'user_count': 16,\
          \ 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain': u'apertureqa1.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO:\
          \ {'domain': u'yahoo.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@lizzy.com'}\nINFO: {'domain': u'alvisocorp.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain':\
          \ u'apertureatf.com', 'user_count': 2, 'external': True, 'cs_user': 'service@lizzy.com'}\n\
          INFO: {'domain': u'aperturesync.onmicrosoft.com', 'user_count': 2, 'external':\
          \ True, 'cs_user': 'service@lizzy.com'}\nINFO: {'domain': u'altoscorp.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@lizzy.com'}\nINFO:\
          \ {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@lizzy.com'}\nINFO: #domains=22\n2020-02-28 19:48:09,184\
          \ MainThread spark-domain-count-lizzy: INFO: user-counts-by-domain: time\
          \ to process people table=0.76\n2020-02-28 19:48:09,184 MainThread spark-domain-count-lizzy:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:48:09,184 MainThread spark-domain-count-lizzy: INFO: user-counts-by-domain.interval=0.77\n"
        pid: null
        result: lizzy:domain-count, pid=20350 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='lizzy', use_elasticsearch=False)\n\
          2020-02-28 19:44:50,584 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/lizzy/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:44:50,588 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/lizzy/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:44:50,592 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/lizzy/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:44:50,592 MainThread spark-people-sort-lizzy:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='lizzy', use_api=True, use_elasticsearch=False)\n\
          20/02/28 19:44:51 WARN NativeCodeLoader: Unable to load native-hadoop library\
          \ for your platform... using builtin-java classes where applicable\n20/02/28\
          \ 19:44:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting\
          \ port 4041.\n20/02/28 19:44:51 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4041. Attempting port 4042.\n20/02/28 19:44:51 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n\
          20/02/28 19:44:51 WARN Utils: Service 'SparkUI' could not bind on port 4043.\
          \ Attempting port 4044.\n20/02/28 19:44:51 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\n\r[Stage 0:>               \
          \                                         (0 + 36) / 36]\r[Stage 0:=>  \
          \                                                     (1 + 35) / 36]\r[Stage\
          \ 0:===>                                                     (2 + 34) /\
          \ 36]\r[Stage 0:=======>                                               \
          \  (5 + 31) / 36]\r[Stage 0:===========>                               \
          \              (7 + 29) / 36]\r[Stage 0:============>                  \
          \                          (8 + 28) / 36]\r[Stage 0:==============>    \
          \                                      (9 + 27) / 36]\r[Stage 0:=================>\
          \                                      (11 + 25) / 36]\r[Stage 0:==================>\
          \                                     (12 + 24) / 36]\r[Stage 0:====================>\
          \                                   (13 + 23) / 36]\r[Stage 0:========================>\
          \                               (16 + 20) / 36]\r[Stage 0:==========================>\
          \                             (17 + 19) / 36]\r[Stage 0:============================>\
          \                           (18 + 18) / 36]\r[Stage 0:================================>\
          \                       (21 + 15) / 36]\r[Stage 0:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 0:==========================================>\
          \              (27 + 9) / 36]\r[Stage 0:============================================>\
          \            (28 + 8) / 36]\r[Stage 0:=============================================>\
          \           (29 + 7) / 36]\r[Stage 0:===============================================>\
          \         (30 + 6) / 36]\r[Stage 0:=================================================>\
          \       (31 + 5) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: lizzy:people-sort, status=zombie, state=finished
        state: finished
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        box_download_image_files: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          enable_syslog_enhancement: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        debug_mode: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          aperture-dss:
            dss-enabled: 'True'
            enable-metrics-test: 'true'
          disable_tika_extraction_on_xml: 'true'
          dss-enabled: 'true'
          ocr-enabled: 'true'
        dss-enabled: 'false'
        fe:
          auto_assign_incidents:
            enabled: 'true'
          dlp_licensing:
            enabled: 'false'
          dss:
            direct_to_mgmt: 'true'
          group_based_policies:
            enabled: 'true'
          group_based_visibility:
            enabled: 'true'
          office365_selective_scan:
            enabled: 'true'
          quip:
            enabled: 'true'
          rbac_teams:
            enabled: 'true'
          show_dlp_licensing_prompt:
            enable: 'true'
            enabled: 'true'
          show_old_data_patterns:
            enabled: 'true'
        group_based_policies:
          enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'false'
        wfm:
          enabled: 'true'
          expanded_types_enabled: 'true'
          malware_analysis_status_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(Ae+WLgz7MM/eIGKcSSBo0w/4ObBwrNJbXhTgj9Bup1LiDe3V6gVIzQ==)
        POSTGRES_SCHEMA_NAME: cs_lizzy
        POSTGRES_USER: ENC(M5NS5Yz5+FA3CsFODmYX1t6vwUOQWKBHKevUWOMIxy4=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_lizzy
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_lizzy
        MONGODB_TENANTDB_PWD: ENC(2dA5XMWxV7NJZZzMOqIQxS/22dPPOPjxnfFq/+pwJ37cntIovBfYiA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(Izr63LXv8rLJGFdYcA34VLbGzuQaUnkbsFMsSn03BGw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.74.2437
      fe: 0.0.dss.269
      worker: 3.13.102.d6
  makhtar:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''makhtar'')

          2020-02-28 19:48:02,894 MainThread spark-people-sort-makhtar: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''makhtar'')

          20/02/28 19:48:03 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:48:04 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:48:04 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:48:04 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:48:04 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:48:04 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=makhtar,build=1.0.32.b145,migrated=True,tenant=makhtar,category=es_ip,subcategory=es_source_code:743

          '
        pid: null
        result: makhtar:analyze-ml, pid=20468 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:42:41 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:42:41 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:42:41\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:42:41 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:42:41 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:42:41 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:42:41 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:42:41\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:42:41 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:42:41 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:42:41 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:42:41 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:42:41\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:42:41 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: makhtar:domain-count, pid=73512 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:51:13 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:51:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:51:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:51:13 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:51:13 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:51:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:51:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:51:13 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:51:13 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:51:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:51:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:51:13 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.70795
        result: makhtar:people-sort, pid=70795 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(r14Hdt2joIqr8i8jyGMTom6SPEYKgDhnjxmxS5iB8aMfCCa43oiPng==)
        POSTGRES_SCHEMA_NAME: cs_makhtar
        POSTGRES_USER: ENC(o35HszZ0uIQ0ORR5mEi4Gpz7bVUUvNGTynMOvFMJAgI=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_makhtar
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_makhtar
        MONGODB_TENANTDB_PWD: ENC(52v3l4QV+fnCYsV85pngXpNUQtwaV+vRhkXBzXxej09TtMobONUnWg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(/6iUuMc1zBYmRp6EjOe5pPqvlJNXaYIQckcad0dLzg4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  mar28issue:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
          rbac:
            local_or_sso_auth: null
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(eXmHe3uEAZQ5PqvtZB4DUpLN1dFjAHlhFLbv8kFesGMBtLHSAGsCHw==)
        POSTGRES_SCHEMA_NAME: cs_mar28issue
        POSTGRES_USER: ENC(8Yz0bNuspnUQoVIHAWGSexTSGvtfwcYi/1wUOicmwTQ=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_mar28issue
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_mar28issue
        MONGODB_TENANTDB_PWD: ENC(GLWTif6DE44eYwwA8hePKq/VgYJRazeJn4R8zzgHvhCE7ypf9rjDog==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(hGLQPHWibVgJUSlFOzBhmr9q3xXo3KWz/9MAvcrG/kE=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  mar4tenant:
    ? ''
    : null
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        dss:
          scan:
            ml:
              shadow_production_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
  megdss0912:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='megdss0912')\n\
          2020-02-28 19:50:23,780 MainThread spark-people-sort-megdss0912: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='megdss0912')\n20/02/28 19:50:24 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:50:25 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:50:25\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:50:25 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:50:25 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          Traceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: ip-10-3-7-96.55884
        result: megdss0912:analyze-ml, pid=55884 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:43:36 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"megdss0912.com\"\
          \n]\n20/02/28 19:43:37 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:43:37 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 3:=============================>                             (1 + 1) /\
          \ 2]\r                                                                 \
          \               \rINFO: writing 7 domains to Mongo\nupsert_domain: boxdevedition.com\n\
          upsert_domain: cirrotester.com\nupsert_domain: paloaltonetworks.com\nupsert_domain:\
          \ aperturead1.com\nupsert_domain: gmail.com\nupsert_domain: apertureqa.com\n\
          upsert_domain: apertureqa1.com\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@megdss0912.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'gmail.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@megdss0912.com'}\nINFO: {'domain': u'boxdevedition.com', 'user_count':\
          \ 23, 'external': True, 'cs_user': 'service@megdss0912.com'}\nINFO: {'domain':\
          \ u'cirrotester.com', 'user_count': 1, 'external': True, 'cs_user': 'service@megdss0912.com'}\n\
          INFO: {'domain': u'aperturead1.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@megdss0912.com'}\nINFO: {'domain': u'paloaltonetworks.com',\
          \ 'user_count': 4, 'external': True, 'cs_user': 'service@megdss0912.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@megdss0912.com'}\nINFO: {'domain': u'apertureqa.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@megdss0912.com'}\n\
          INFO: #domains=7\n2020-02-28 19:43:38,476 MainThread spark-domain-count-megdss0912:\
          \ INFO: user-counts-by-domain: time to process people table=1.31\n2020-02-28\
          \ 19:43:38,476 MainThread spark-domain-count-megdss0912: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.10\n2020-02-28 19:43:38,476 MainThread\
          \ spark-domain-count-megdss0912: INFO: user-counts-by-domain.interval=1.41\n"
        pid: null
        result: megdss0912:domain-count, pid=86249 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='megdss0912', use_elasticsearch=False)\n\
          2020-02-28 19:47:09,431 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/megdss0912/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:47:09,437 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/megdss0912/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:47:09,440 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/megdss0912/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:47:09,441 MainThread spark-people-sort-megdss0912:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='megdss0912', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:47:09 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:47:10 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:47:10\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:47:10 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:47:10 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          fatal: Not a git repository (or any of the parent directories): .git\nfatal:\
          \ Not a git repository (or any of the parent directories): .git\n\r[Stage\
          \ 0:>                                                         (0 + 0) /\
          \ 36]\r[Stage 0:>                                                      \
          \  (0 + 36) / 36]\r[Stage 0:=>                                         \
          \              (1 + 35) / 36]\r[Stage 0:=================>             \
          \                         (11 + 25) / 36]\r[Stage 0:============================================>\
          \            (28 + 8) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r                                                   \
          \                             \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: megdss0912:people-sort, pid=11931 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(t9jCDjaipsk+ZvcaKX9Qf7PcqSVSksEA4++KDd2OEzP9CWTqcyG+Ig==)
        POSTGRES_SCHEMA_NAME: cs_megdss0912
        POSTGRES_USER: ENC(3S1BVrAsm+V6X9sW34/zBO6+EfLPgXOBsjeAtqGH5k8=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_megdss0912
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_megdss0912
        MONGODB_TENANTDB_PWD: ENC(2VoLGthwd539lVbFaW7hjikmFgCNFZpWVKdgq3ijLLL+NIamJ7We/A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(K9xBWxK2Cwnsw4sgQ8oJCuNSZOUubPi96p7FoP9I/Fw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.57.2055
      fe: 0.0.DLP.593
  megdss0926:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='megdss0926')\n\
          2020-02-28 19:45:39,829 MainThread spark-people-sort-megdss0926: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='megdss0926')\n20/02/28 19:45:40 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:45:41 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:45:41\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:45:41 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:45:41 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          Traceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: megdss0926:analyze-ml, pid=120626 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:247)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat.getSplits(EsInputFormat.java:457)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat.getSplits(EsInputFormat.java:438)\n\
          \tat org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:46:32 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"megdss0926.com\"\
          \n]\n20/02/28 19:46:32 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:46:32 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 4:=============================>                             (1 + 1) /\
          \ 2]\r                                                                 \
          \               \rINFO: writing 1 domains to Mongo\nupsert_domain: paloaltonetworks.com\n\
          INFO: ------------------------------------------------\nINFO: user counts\
          \ by domain: service@megdss0926.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'paloaltonetworks.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@megdss0926.com'}\nINFO: #domains=1\n2020-02-28 19:46:33,250\
          \ MainThread spark-domain-count-megdss0926: INFO: user-counts-by-domain:\
          \ time to process people table=0.98\n2020-02-28 19:46:33,250 MainThread\
          \ spark-domain-count-megdss0926: INFO: user-counts-by-domain: time to write\
          \ to mongo/elasticsearch=0.02\n2020-02-28 19:46:33,251 MainThread spark-domain-count-megdss0926:\
          \ INFO: user-counts-by-domain.interval=0.99\n"
        pid: null
        result: megdss0926:domain-count, pid=1082 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.84674
        result: 'action: state=running'
        state: running
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'false'
          show_dlp_licensing_prompt:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(MJVcLWQE2Io12hmM2ySzes86LDnTT1Z9e0C9VqUpVJNvNvktdpha8w==)
        POSTGRES_SCHEMA_NAME: cs_megdss0926
        POSTGRES_USER: ENC(q/x8rZGCIkjlbyJtproMLF+aVwOg7Nloiqwvi+e/GJo=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_megdss0926
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_megdss0926
        MONGODB_TENANTDB_PWD: ENC(FDOD9OFARiTQab23vjgcPImiBLIRfGjD2giXgveuuO0AD68ZSpr6sw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(1RijlDhOxSGf8vID37+trnYxUGgv+g2CsE4I6SnrMq0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.57.2056
      fe: 4.1.208
      worker: 3.13.56.d2
  mkhan2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
          sspm:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fedev.702
  mminkov:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
          sspm:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  mongo40:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.380-es7
  multitenant1118:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  multitestdev:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  multitestdev1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(b1dRzY1epQ4SonU0XaK/FXIF+glu0hie/gjksvbu2hJtraqn8KVhTQ==)
        POSTGRES_SCHEMA_NAME: cs_multitestdev1
        POSTGRES_USER: ENC(MY0VXEnWCpjsgHxtUBIiJLb5+JT/psuEXhm1biEubio=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_multitestdev1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_multitestdev1
        MONGODB_TENANTDB_PWD: ENC(VtFrKwWk2NtrZxpB0tk5HRwg+HZYWpjPRXfcL4bto/iWL54JukGLgQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(7EAhZg8lLEQpUrhfxfqdcXCyo/VGMPb0qtL44aLAVnw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  multitestdev2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(vzJi2hN7wljX1mlGMSrcxlbpEnCkXc6yBsCkr4ElRtVpKe7M/BwhhQ==)
        POSTGRES_SCHEMA_NAME: cs_multitestdev2
        POSTGRES_USER: ENC(AmKCWuRTsC4ox8T9tvFAm6uZJyBx7y89X8yosnk4R5g=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_multitestdev2
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_multitestdev2
        MONGODB_TENANTDB_PWD: ENC(CL/uIt+EQFX0mvciL4muiQeLXvgvXFwDShT7I8GsDBfvhh054Ayh2A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(SVOcs1nXmu/aQzZRH1DOTsWjxSNknBJ9yXjzcA9ZC6Q=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ngcasb1:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          data_violations:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'false'
          rbac:
            local_or_sso_auth: 'true'
          sspm:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        ngcasb:
          discovered_apps:
            enabled: 'True'
          posture_security:
            enabled: 'True'
          sanctioned_apps:
            enabled: 'True'
          sync_user_management:
            enabled: 'True'
          ueba:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(ENqI8RYwBNEJXhOVbLi9r4o/oh3aak1pag0OvPbMxtQEcEAFGvVIvA==)
        POSTGRES_SCHEMA_NAME: cs_ngcasb1
        POSTGRES_USER: ENC(/Qnub4b038NA3tTlbyKPyejnZXJQodKEk3fJ10zPHpg=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ngcasb1
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ngcasb1
        MONGODB_TENANTDB_PWD: ENC(QGyvFFGUBalSBIQqq1gtU7SpvZUSomczT1qE+jLzTFdx0NXiBA89wg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(SY1r5hfPG2zoMf/jhnG90TgAJ5GLxrPhK/uyhxks5tw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.ueba.704
  ngcasbtest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  nitesh:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(11ATRbYLmNQNsacdzIHBhTxmcsnKIOMj9SfDdAwDkS8/SD4Wb/BfkA==)
        POSTGRES_SCHEMA_NAME: cs_nitesh
        POSTGRES_USER: ENC(GgCfx8I1R/nzrV1rNis16+WxZcErsWNlSSEEpxLoVXk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_nitesh
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_nitesh
        MONGODB_TENANTDB_PWD: ENC(plOWoeWW08n+c6Zx4B7K9vHxbJv46MQIGb9qCWa/vzhh9Ow9+howIQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(9zb2NFpHjopLUueTMj1phzDplNnvJj5pDhvhKYjMPXM=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  nov17tenant:
    config:
      v1:
        dss:
          scan:
            content_extraction:
              enable_v2_service: 'true'
  paloaltonetworks89:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  paloaltonetworks89stream:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(cpKbGywkK+gmGGdiTmUi3EsbRrcSHF8P+WpgOV18UNIRtX9GMnqOPg==)
        POSTGRES_SCHEMA_NAME: cs_paloaltonetworks89stream
        POSTGRES_USER: ENC(5Db3FMxSz3uzxLhJEvQ2sHqm+0CyfGkJNimhIS/GSoM=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_paloaltonetworks89stream
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_paloaltonetworks89stream
        MONGODB_TENANTDB_PWD: ENC(QzGViLT8biw98TkTvyPbaO0iGS03SiVjlUORI2AYuDL2FMPMv6qVRg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(A4Ct7XTBg58KgRy2DYrpkRg8eyOxiPBwCCefQSA2BA0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  panwfawkes1112021:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  psdlptenant:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        apps:
          msteams:
            webhooks:
              ignore_token_expiration: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          asset_scan_enabled: 'True'
          async_enabled: 'True'
          dss-enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          data_violations:
            enabled: 'true'
          debug_mode: 'true'
          dlp_licensing:
            show_prompt: 'false'
          dss:
            snippets_by_confidence_level: 'true'
          gamma:
            enabled: 'false'
            violations: 'true'
          gdrivev2:
            enabled: 'False'
          pan_sso:
            enabled: 'false'
          rbac:
            local_or_sso_auth: 'true'
          slackstandard:
            enabled: 'true'
          zoom:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          o365:
            enable_active_list_scheduling: 'false'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(3HXW7FKa2eWMZCMkiNZtBdQ7tXU2fjFTi9XhS0MXJanhMJq6aPvm4A==)
        POSTGRES_SCHEMA_NAME: cs_psdlptenant
        POSTGRES_USER: ENC(ovGZ6tGFIyLOb2FJTowEb2izW+rDx17mP/GMDS5UXo0=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_psdlptenant
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_psdlptenant
        MONGODB_TENANTDB_PWD: ENC(CWKmr5NIzZtPzjCghnkt6ZHvXmSz50u2spjkg7dyFmqPGARXGdQYhA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(QrW89VVfDzXNoqNpRZj9mehbn6tqDzbJC7w6uYbd3uY=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.async.661
      worker: 3.13.195.d4
      worker-es7x: 3.13.195.d4
  radon:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  ranair:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:48:54 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:48:54 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:48:54\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:48:54 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:48:54 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:48:54 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:48:54 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:48:54\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:48:54 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:48:54 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:48:54 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:48:54 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:48:54\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:48:54 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: ranair:analyze-ml, pid=33800 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:44:25 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"ranair.com\"\
          \n]\n20/02/28 19:44:25 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:44:25 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 3:>                                                          (0 + 2) /\
          \ 2]\r[Stage 3:=============================>                          \
          \   (1 + 1) / 2]\r                                                     \
          \                           \rINFO: writing 9 domains to Mongo\nupsert_domain:\
          \ mail.com\nupsert_domain: boxdevedition.com\nupsert_domain: apertureqa3.onmicrosoft.com\n\
          upsert_domain: hotmail.com\nupsert_domain: gmail.com\nupsert_domain: apertureqa1.com\n\
          upsert_domain: apertureqa7.onmicrosoft.com\nupsert_domain: apertureqa.com\n\
          upsert_domain: apertureqa3.com\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@ranair.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'mail.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@ranair.com'}\nINFO: {'domain': u'boxdevedition.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@ranair.com'}\nINFO: {'domain':\
          \ u'apertureqa3.onmicrosoft.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@ranair.com'}\nINFO: {'domain': u'hotmail.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@ranair.com'}\nINFO: {'domain':\
          \ u'gmail.com', 'user_count': 1, 'external': True, 'cs_user': 'service@ranair.com'}\n\
          INFO: {'domain': u'apertureqa7.onmicrosoft.com', 'user_count': 2, 'external':\
          \ True, 'cs_user': 'service@ranair.com'}\nINFO: {'domain': u'apertureqa.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@ranair.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@ranair.com'}\nINFO: {'domain': u'apertureqa3.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@ranair.com'}\n\
          INFO: #domains=9\n2020-02-28 19:44:28,825 MainThread spark-domain-count-ranair:\
          \ INFO: user-counts-by-domain: time to process people table=3.04\n2020-02-28\
          \ 19:44:28,825 MainThread spark-domain-count-ranair: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.11\n2020-02-28 19:44:28,825 MainThread\
          \ spark-domain-count-ranair: INFO: user-counts-by-domain.interval=3.15\n"
        pid: null
        result: ranair:domain-count, pid=100002 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='ranair', use_elasticsearch=False)\n\
          2020-02-28 19:49:07,708 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/ranair/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:49:07,712 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/ranair/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:49:07,715 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/ranair/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:49:07,715 MainThread spark-people-sort-ranair:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='ranair', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:49:08 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:49:08\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:49:08 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:49:08\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4047. Attempting port 4048.\n20/02/28 19:49:08 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n\
          20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not bind on port 4049.\
          \ Attempting port 4050.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4050. Attempting port 4051.\n20/02/28 19:49:08\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting\
          \ port 4052.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4052. Attempting port 4053.\n20/02/28 19:49:08 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4053. Attempting port 4054.\n\
          20/02/28 19:49:08 WARN Utils: Service 'SparkUI' could not bind on port 4054.\
          \ Attempting port 4055.\n20/02/28 19:49:08 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4055. Attempting port 4056.\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\nfatal: Not a git repository\
          \ (or any of the parent directories): .git\n\r[Stage 0:>               \
          \                                          (0 + 0) / 36]\r[Stage 0:>   \
          \                                                     (0 + 36) / 36]\r[Stage\
          \ 0:==================================================>      (32 + 4) /\
          \ 36]\r[Stage 0:====================================================>  \
          \  (33 + 3) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: ranair:people-sort, pid=39208 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          saved_filters_incidents:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(Y3ioL72LXL6fEyGcZRGacaCkmPCMK897tnoL211TRNzMxoI6XJ7IWA==)
        POSTGRES_SCHEMA_NAME: cs_ranair
        POSTGRES_USER: ENC(VBgxv1iV42yo+MJgiyQ6TVVEi9mYx0Rw0Qwx4mtMyI4=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_ranair
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_ranair
        MONGODB_TENANTDB_PWD: ENC(1Cwim6WLIZ37+seU8TL/MP8Hn9iKsG9/6J4h69QyP4GcapAMSiKayA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(/Q5TW3JfxPrERVKnvRf68tz40IUKZbOr3TG/V4gcoa0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.53.1991
      fe: 0.0.dev.629
      worker: 3.13.53.d1
  schaies7:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        directory-service:
          enable_delta_crawling: 'true'
          max_catalog_size: '2'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'false'
        file_cache_enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          o365:
            enable_active_list_scheduling: 'false'
            enable_active_sites_scheduling: 'false'
            enable_active_users_cache: 'false'
            fetch_user_logins: 'true'
          queuecriteria:
            peak_hours_scan_disabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(tKrv6viP09mAaMaLx7lS0igb+7aT5kThOK4r8Gy/uJ9Xt6rUsGVJdA==)
        POSTGRES_SCHEMA_NAME: cs_schaies7
        POSTGRES_USER: ENC(XWPnvp5UPLg8gN8u0ASi4XqIgNrPbACY02ztnrCKejk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_schaies7
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_schaies7
        MONGODB_TENANTDB_PWD: ENC(JIStpZMWiAPfN5et+oHGVTM0Ur6oymf93mSSuktNLypPvfQZcUufwg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(1tDOp5JDJQtSWQJxM8DxkqrE+y3e7D0w9e+Ct27b7Wo=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  securityrisk:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  selftest:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    versions:
      fe: 4.1.388
  selftest_dss:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    versions:
      fe: 4.1.363
  selftestdss:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    versions:
      fe: 4.1.364
  sugowda:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''sugowda'')

          2020-02-28 19:43:43,100 MainThread spark-people-sort-sugowda: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''sugowda'')

          20/02/28 19:43:43 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4051. Attempting port 4052.

          20/02/28 19:43:44 WARN Utils: Service ''SparkUI'' could not bind on port
          4052. Attempting port 4053.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=sugowda,build=1.0.32.b145,migrated=True,tenant=sugowda,category=es_ip,subcategory=es_source_code:840

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=sugowda,build=1.0.32.b145,migrated=True,tenant=sugowda,category=es_legal,subcategory=es_bankruptcy_filings:48

          '
        pid: null
        result: sugowda:analyze-ml, pid=90607 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:45:52 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"sugowda.com\"\
          \n]\n20/02/28 19:45:53 WARN EsInputFormat: Cannot determine task id...\n\
          INFO: writing 9 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@sugowda.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'paloaltonetworks.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@sugowda.com'}\nINFO: {'domain': u'apertureatf.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@sugowda.com'}\n\
          INFO: {'domain': u'gmail.com', 'user_count': 5, 'external': True, 'cs_user':\
          \ 'service@sugowda.com'}\nINFO: {'domain': u'apertureqa1.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@sugowda.com'}\nINFO: {'domain':\
          \ u'probeapertureus.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@sugowda.com'}\nINFO: {'domain': u'apertureqa.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@sugowda.com'}\nINFO: {'domain':\
          \ u'prismasaasdev.com', 'user_count': 1, 'external': True, 'cs_user': 'service@sugowda.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@sugowda.com'}\nINFO: {'domain': u'apertureqa3.com',\
          \ 'user_count': 3, 'external': True, 'cs_user': 'service@sugowda.com'}\n\
          INFO: #domains=9\n2020-02-28 19:45:53,667 MainThread spark-domain-count-sugowda:\
          \ INFO: user-counts-by-domain: time to process people table=0.68\n2020-02-28\
          \ 19:45:53,667 MainThread spark-domain-count-sugowda: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.00\n2020-02-28 19:45:53,668 MainThread\
          \ spark-domain-count-sugowda: INFO: user-counts-by-domain.interval=0.69\n"
        pid: null
        result: sugowda:domain-count, pid=122789 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='sugowda', use_elasticsearch=False)\n\
          2020-02-28 19:44:25,908 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/sugowda/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:44:25,915 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/sugowda/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:44:25,919 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/sugowda/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:44:25,920 MainThread spark-people-sort-sugowda:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='sugowda', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:44:26 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:44:27 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4047. Attempting port 4048.\n20/02/28 19:44:27 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n\
          20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port 4049.\
          \ Attempting port 4050.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4050. Attempting port 4051.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting\
          \ port 4052.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4052. Attempting port 4053.\n20/02/28 19:44:27 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4053. Attempting port 4054.\n\
          20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port 4054.\
          \ Attempting port 4055.\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\n\r[Stage 0:>                                     \
          \                   (0 + 36) / 36]\r[Stage 0:=>                        \
          \                               (1 + 35) / 36]\r[Stage 0:===>          \
          \                                           (2 + 34) / 36]\r[Stage 0:====>\
          \                                                    (3 + 33) / 36]\r[Stage\
          \ 0:======>                                                  (4 + 32) /\
          \ 36]\r[Stage 0:=======>                                               \
          \  (5 + 31) / 36]\r[Stage 0:=========>                                 \
          \              (6 + 30) / 36]\r[Stage 0:===========>                   \
          \                          (7 + 29) / 36]\r[Stage 0:===============>   \
          \                                     (10 + 26) / 36]\r[Stage 0:=================>\
          \                                      (11 + 25) / 36]\r[Stage 0:==================>\
          \                                     (12 + 24) / 36]\r[Stage 0:=======================>\
          \                                (15 + 21) / 36]\r[Stage 0:========================>\
          \                               (16 + 20) / 36]\r[Stage 0:============================>\
          \                           (18 + 18) / 36]\r[Stage 0:=============================>\
          \                          (19 + 17) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:================================>\
          \                       (21 + 15) / 36]\r[Stage 0:==================================>\
          \                     (22 + 14) / 36]\r[Stage 0:===================================>\
          \                    (23 + 13) / 36]\r[Stage 0:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 0:======================================>\
          \                 (25 + 11) / 36]\r[Stage 0:============================================>\
          \            (28 + 8) / 36]\r[Stage 0:=============================================>\
          \           (29 + 7) / 36]\r[Stage 0:===============================================>\
          \         (30 + 6) / 36]\r[Stage 0:=================================================>\
          \       (31 + 5) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: sugowda:people-sort, pid=102657 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(6rQ1q92Hoi2jZpfLqoxhbXOOQddpN+r2FbKU0ccjLjq2Urr2SPFl0Q==)
        POSTGRES_SCHEMA_NAME: cs_sugowda
        POSTGRES_USER: ENC(7L29WvUeeEAN+dVCH12q5Ric7vmlwaR7mEO4yKsSnZA=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_sugowda
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_sugowda
        MONGODB_TENANTDB_PWD: ENC(3M/6xiNLhJqQvQxLLbpJpgWAjjdg10l8BBukZWtcBzwre2BIqFcRMw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(uJltrenhq7JQsJBhHCRFeRxvUIoJyBvogt9JFHFsKQg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: null
  supadhya2dss:
    apilayer:
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        worker:
          processing_mode: REMEDIATION_ONLY
    versions:
      autolib: 1.74.2471
      fe: 4.1.209
      worker: 3.13.96.d2
  supadhyadss:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='supadhyadss')\n\
          2020-02-28 19:45:49,248 MainThread spark-people-sort-supadhyadss: INFO:\
          \ Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='supadhyadss')\n\
          20/02/28 19:45:49 WARN NativeCodeLoader: Unable to load native-hadoop library\
          \ for your platform... using builtin-java classes where applicable\nTraceback\
          \ (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: supadhyadss:analyze-ml, pid=122994 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.77425
        result: 'action: state=running'
        state: running
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''supadhyadss'', use_elasticsearch=False)

          2020-02-28 19:46:07,311 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/supadhyadss/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:46:07,317 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/supadhyadss/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:46:07,321 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/supadhyadss/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:46:07,321 MainThread spark-people-sort-supadhyadss: INFO:
          Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''supadhyadss'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:46:07 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:46:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:46:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:46:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:46:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:46:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: supadhyadss:people-sort, pid=127649 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          aperture-dss:
            dss_worker_queue_dedup_enabled: 'true'
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(SOF1APkSVmGk5uiT7PBFhKj+omfxtCZPXMZto735UNVGHWElqDuZGg==)
        POSTGRES_SCHEMA_NAME: cs_supadhyadss
        POSTGRES_USER: ENC(c4K3eQh0WVEuWOhltmBc/iMeuVfWXscHqy0LdzJywow=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_supadhyadss
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_supadhyadss
        MONGODB_TENANTDB_PWD: ENC(5Tkw6dauPnSolsImC57qKjmjFBg3Dw5qpoNDcTvLtIwTrrondgNjAA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(EgArsSeYw16bU6GsvBk23Z8oglIsRSRfCRH/9qmQ0ro=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.48.1951
      fe: 3.13.52.1
      worker: 3.13.52.d2
  supadhyadss2020:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        box_download_image_files: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
          ocr-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7
        QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(//muZ/ueaD3VSsqm5tTn7pn6AB+C9FPVb/gQDifBQ0cGYDOoS/2cXw==)
        POSTGRES_SCHEMA_NAME: cs_supadhyadss2020
        POSTGRES_USER: ENC(Fe5OKjLtiyS1PF+s50RYjK2nsvbhqzwE5cGPbQ391Zk=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_supadhyadss2020
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_supadhyadss2020
        MONGODB_TENANTDB_PWD: ENC(I8iLhrOJ5Eihh7iL3++A3M+ERmPk5bYNXeiqyRByTDBC6UBRiBMymg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(KjMEh0EsXpEYipoH4muuekSViOsAXLyhzJe4onL4GpQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.209
      worker: 3.13.96.d2
  surya0107:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:49:46 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:49:46 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:49:46\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:49:46 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:49:46 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:49:46 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:49:46 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:49:46\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:49:46 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:49:46 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:49:46 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:49:46 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:49:46\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:49:46 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: surya0107:analyze-ml, pid=48022 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:50:35 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:50:35 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:50:35 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.61610
        result: surya0107:domain-count, pid=61610 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.75485
        result: 'action: state=running'
        state: running
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(GjL67oJ8Dcqj13NvN7axqfES4YFCdXs0m2f/29MTsO/Z7r8PL9/siw==)
        POSTGRES_SCHEMA_NAME: cs_surya0107
        POSTGRES_USER: ENC(FJZQzeyNXABOXn+L+P9wAzG3ZmmuGf09ogu9CvoB+7s=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_surya0107
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_surya0107
        MONGODB_TENANTDB_PWD: ENC(iagqveugpq3T8gJtrEiSoLY8ewfswDHz+OZa0iNW5jzCFEf47KIkCw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(7Lp5MSjvVke0KErVP5AndwbUl8I9lCZNLLlWGT7lEqw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  surya0819:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:49:47 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:49:47 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:49:47\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:49:47 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:49:47 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:49:47 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:49:47 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:49:47\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:49:47 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:49:47 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:49:47 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:49:47 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:49:47\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:49:47 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: surya0819:analyze-ml, pid=48292 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:48:58 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:48:58 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:48:58\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:48:58 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:48:58 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:48:58 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:48:58 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:48:58\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:48:58 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:48:58 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:48:58 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:48:58 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:48:58\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:48:58 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: surya0819:domain-count, pid=35638 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''surya0819'', use_elasticsearch=False)

          2020-02-28 19:44:27,208 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya0819/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:44:27,215 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya0819/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:44:27,219 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya0819/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:44:27,220 MainThread spark-people-sort-surya0819: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''surya0819'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:44:27 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: surya0819:people-sort, pid=103175 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        box_download_image_files: 'true'
        data-pattern:
          data_policy_email_digest: 'true'
          delay_wildfire_submission_sec: '120'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          ? ''
          : null
          dss-enabled: 'true'
          ocr-enabled: 'true'
        fe:
          dlp_licensing:
            enable: 'true'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wfm:
          enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(gTCfCziiEt0mcu6s4N9dmkQxvc/Qz+ylDfsWvA0CJI9K4V8cNxkGlA==)
        POSTGRES_SCHEMA_NAME: cs_surya0819
        POSTGRES_USER: ENC(3Wk62ROpkUD26QBQl1DFsudoqH3hn9jx4L60teYnEro=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_surya0819
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_surya0819
        MONGODB_TENANTDB_PWD: ENC(+DN9fD2Oz03yC1YQ4zYgGsRJZHtHECKJKqMe9mu0xRHN+KYO1Ke18A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(0rL5DeP7zNkloRRk48PIJ1p1e7I4DogB2rFM9l2cRGk=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_without_subscription: 'true'
    versions:
      worker: 3.13.109.4697-dev
  surya1018:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='surya1018')\n2020-02-28\
          \ 19:48:13,587 MainThread spark-people-sort-surya1018: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='surya1018')\n20/02/28 19:48:14 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:48:14 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\nTraceback (most recent\
          \ call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: surya1018:analyze-ml, pid=22662 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: 'upsert_domain: cirrosecure.com

          upsert_domain: garlic.com

          upsert_domain: probeapertureus.com

          upsert_domain: prismasaasdev.com

          upsert_domain: yahoo.co.in

          upsert_domain: boxdevedition.com

          upsert_domain: cirrotester.com

          upsert_domain: hotmail.com

          upsert_domain: xoriant.com

          upsert_domain: gmail.com

          upsert_domain: apertureqa1.com

          upsert_domain: yahoo.com

          upsert_domain: outlook.com

          upsert_domain: qq.com

          upsert_domain: apertureatf.com

          upsert_domain: apertureqa5.onmicrosoft.com

          upsert_domain: apertureqa7.onmicrosoft.com

          upsert_domain: apertureqa.onmicrosoft.com

          INFO: ------------------------------------------------

          INFO: user counts by domain: service@surya1018.com

          INFO: ------------------------------------------------

          INFO: {''domain'': u''yahoo.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''yahoo.co.in'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''paloaltonetworks.com'', ''user_count'': 10, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''trbvn.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''gmail.com'', ''user_count'': 13, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''hotmail.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa3.onmicrosoft.com'', ''user_count'': 1,
          ''external'': True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''cirrosecure.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''boxdevedition.com'', ''user_count'': 22, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa7.onmicrosoft.com'', ''user_count'': 1,
          ''external'': True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''aperturead1.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa5.onmicrosoft.com'', ''user_count'': 12,
          ''external'': True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''probeapertureus.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''cirrotester.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa.onmicrosoft.com'', ''user_count'': 4, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''xor.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''outlook.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''garlic.com'', ''user_count'': 1, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''xoriant.com'', ''user_count'': 2, ''external'': True,
          ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''qq.com'', ''user_count'': 1, ''external'': True, ''cs_user'':
          ''service@surya1018.com''}

          INFO: {''domain'': u''apertureatf.com'', ''user_count'': 2, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa1.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''prismasaasdev.com'', ''user_count'': 1, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: {''domain'': u''apertureqa3.com'', ''user_count'': 3, ''external'':
          True, ''cs_user'': ''service@surya1018.com''}

          INFO: #domains=25

          2020-02-28 19:44:31,366 MainThread spark-domain-count-surya1018: INFO: user-counts-by-domain:
          time to process people table=0.72

          2020-02-28 19:44:31,367 MainThread spark-domain-count-surya1018: INFO: user-counts-by-domain:
          time to write to mongo/elasticsearch=0.30

          2020-02-28 19:44:31,367 MainThread spark-domain-count-surya1018: INFO: user-counts-by-domain.interval=1.02

          '
        pid: null
        result: surya1018:domain-count, pid=101248 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''surya1018'', use_elasticsearch=False)

          2020-02-28 19:47:55,607 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya1018/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:47:55,613 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya1018/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:47:55,616 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/surya1018/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:47:55,617 MainThread spark-people-sort-surya1018: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''surya1018'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:47:56 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:47:56 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          2020-02-28 19:48:13,587 spark-people-sort-surya1018 INFO Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''surya1018'')

          '
        pid: null
        result: surya1018:people-sort, pid=18547 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          disabled-data-patterns:
            ? ''
            : null
            all: Cloud DB credentials
            ngfw: Cloud DB credentials
            prisma-access: Cloud DB credentials
            prisma-saas: Private key,Api access token,Application credentials,Cloud
              DB credentials
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
          scan:
            disable_tika_extraction_for_xml: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(I+AAlpttnfJTxdq3IFnCOdgghHANQtjjFCWhuwm3VR2p3y9rI4QCKw==)
        POSTGRES_SCHEMA_NAME: cs_surya1018
        POSTGRES_USER: ENC(DOuYvZLXaK7ZG5wwO5rxzhe6Ouo//pMauOsRQBBkrCY=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_surya1018
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_surya1018
        MONGODB_TENANTDB_PWD: ENC(9nnH7upw6wjjN81MTO9DElIetHbhQqEJpUM6Q6Lqu8lhobpWhyrlcg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(CNdLGETBELGEXZF+sYl7c4JgXa+eF3WyhzuAkRqqVWY=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  suryaclstg2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  suryastg2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  tajtest1:
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'False'
    config:
      v1:
        skip_rta_processing: 'True'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        ES_QUERY_HOST: 10.3.0.76
  tajtest2:
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        skip_rta_processing: 'False'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        ES_QUERY_HOST: 10.3.0.76
  tajtest3:
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'True'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        skip_rta_processing: 'True'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        ES_QUERY_HOST: 10.3.0.76
  test_tenant:
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'False'
    config:
      v1:
        skip_rta_processing: 'True'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        ES_QUERY_HOST: 10.3.0.76
  testprov1119:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  testprov1123:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  testprovstg2:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  testrar:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(rpW8SxS4bO5jCWssTG3u8zpbiVtDfYrAux+gUITdPtrBNEioo0jbRw==)
        POSTGRES_SCHEMA_NAME: cs_testrar
        POSTGRES_USER: ENC(0B05y03dyxCxxgyHlPADIRD/KbNNhkzEVaDLmhhD474=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_testrar
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_testrar
        MONGODB_TENANTDB_PWD: ENC(ryW6RDtC7y9Zvh9Y0XwZwR4lkA8+BFf2d70H/zXkFFH7FB/tx1ragw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(gg7SN98zIN6bLre7xwDEVn40/ZHj7wjJdQrSmcWcXlg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  testtenant01212022:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  thanos:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(gi+NJ5HkOKKX0ugsweR8YlvEjFgNrUQbYAO64Y6mnNYNxV+1h7OnaA==)
        POSTGRES_SCHEMA_NAME: cs_thanos
        POSTGRES_USER: ENC(mzg2kIifmWp51jglbG1GaEHvNrf2ZrW0JnpEnyoFj34=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_thanos
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_thanos
        MONGODB_TENANTDB_PWD: ENC(dP50O9DBPPwxaNybRYJWiVp/eR9xJlSC7ETyvVT9GBr6VjKmQIQJvQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(1R/fSACEO5cwBe0KI2CWPoHlKnUKz0FglSu8REWk8so=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.347-es7
      fe-es7x: 4.1.347-es7
  tjliu:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''tjliu'')

          2020-02-28 19:43:45,503 MainThread spark-people-sort-tjliu: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''tjliu'')

          20/02/28 19:43:45 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:43:46 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tjliu,build=1.0.32.b145,migrated=True,tenant=tjliu,category=es_ip,subcategory=es_source_code:898

          '
        pid: null
        result: tjliu:analyze-ml, pid=91437 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:45:13 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:45:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:45:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:45:13 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:45:13 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:45:13 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:45:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:45:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:45:13 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:45:13 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:45:13 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:45:13 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:45:13\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:45:13 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: tjliu:domain-count, pid=112420 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:49:53 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:49:53 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:49:53\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:49:53 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:49:53 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:49:53 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:49:53 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:49:53\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:49:53 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:49:53 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:49:53 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:49:53 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:49:53\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:49:53 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: tjliu:people-sort, pid=50604 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        REMEDIATION_API_CALL_LIMIT: '-1'
        box_expired_link_fetch_interval_in_sec: '86400'
        data-pattern:
          data_policy_email_digest: 'true'
          expediate_processing: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dropbox_expired_link_fetch_interval_in_sec: '86400'
        dss:
          dss-enabled: 'false'
        enable_event_propagation_deduping: 'true'
        fe:
          active_directory:
            enabled: 'true'
          assets_search:
            debug: 'true'
            fast_mode: 'true'
          auto_assign_incidents:
            enabled: 'true'
          gmail:
            enabled: 'true'
          google_whitelist_emails: qa@apertureqa.com, user.1@apertureqa3.com, user.1@apertureqa1.com
          group_based_policies:
            enabled: 'true'
          group_based_visibility:
            enabled: 'true'
          health_metrics:
            ? ''
            : null
            enabled: 'true'
          i18n:
            enable: 'true'
          multi_factor_authentication:
            enabled: 'true'
          office365_selective_scan:
            enabled: 'true'
          paas:
            enable: 'false'
          pan_sso:
            enabled: 'False'
          rbac:
            ? ''
            : null
            expanded_quarantine: 'true'
          rbac_teams:
            enabled: 'true'
          saml:
            enable: 'true'
          saml_proxy:
            enabled: 'false'
          snippets:
            enabled: 'true'
          workplace:
            enabled: 'true'
        group_based_policies:
          enabled: 'true'
        health_metrics:
          ? ''
          : null
          emails: kkrenrich@paloaltonetworks.com
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        slack:
          refresh_channel_exposure_frequency_in_min: '5'
        wfm:
          ? ''
          : null
          enabled: 'true'
          expanded_types_enabled: 'true'
          malware_analysis_status_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          awsconsole:
            RATE_LIMIT_PER_SECOND_CONFIG_API: '50'
            RATE_LIMIT_PER_SECOND_EC2_API: '10'
            RATE_LIMIT_PER_SECOND_ELB_API: '5'
            RATE_LIMIT_PER_SECOND_IAM_API: '100'
            RATE_LIMIT_PER_SECOND_S3_API: '100'
            job_interval_in_min: '5'
            paas_enabled: 'true'
            service_discovery_job_interval_in_min: '5'
            settings_enabled: 'false'
          dropbox:
            153849edfae1d369a7a53df1d2fc043f:
              enable_migration: 'true'
            c36a7ab78906a53b193c36547be42756:
              enable_migration: 'true'
            job_internal_in_min: '3'
          processing_mode: REMEDIATION_ONLY
          slack:
            fetch_channels_number_of_items_per_page: '1'
            fetch_dm_channels_number_of_items_per_page: '1'
            offset_based_pagination_enabled: '1'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq2.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(ziPItQmVXTwC3KhocRpzOOEzk9ay+1RJpxic/6k5knLHBxjRgvXaaw==)
        POSTGRES_SCHEMA_NAME: cs_tjliu
        POSTGRES_USER: ENC(M2Ttqz6LuuotK8wikhxevI7Eg5UUAhAuGjq1SqA2ryo=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tjliu
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tjliu
        MONGODB_TENANTDB_PWD: ENC(rus217PzJ/xBtEojmwkx6jqn5WKyozNY27mp4QgQc6dkseAQv9U4Yw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ya9RKQABuvwpidBN/JhkUFiiI/uAuX8emhuduFbHHLA=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq2.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 4.1.246
  tomr:
    analytics:
      $disabled: 'true'
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''tomr'')

          2020-02-28 19:45:51,446 MainThread spark-people-sort-tomr: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''tomr'')

          20/02/28 19:45:51 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:45:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:45:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:45:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:45:52 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_legal,subcategory=es_standard_business_agreements:50085

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_legal,subcategory=es_patent_filings:44

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_finance,subcategory=es_pci_finac:719

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_legal,subcategory=es_merger_acquisition:70

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_finance,subcategory=es_pci_perfi:382

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_legal,subcategory=es_bankruptcy_filings:413

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tomr,build=1.0.32.b145,migrated=True,tenant=tomr,category=es_ip,subcategory=es_source_code:5685

          '
        pid: null
        result: tomr:analyze-ml, pid=123549 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\n\n20/02/28 19:44:31 WARN EsInputFormat: Cannot determine task id...\n\
          INFO: internal_domains==[\n    \"apertureqa.com\", \n    \"apertureqa1.com\"\
          , \n    \"apertureqa3.com\", \n    \"paloaltonetworks.com\"\n]\n20/02/28\
          \ 19:44:31 WARN EsInputFormat: Cannot determine task id...\nINFO: writing\
          \ 27 domains to Mongo\nupsert_domain: apertureqa4.com\nupsert_domain: aperturead2.com\n\
          upsert_domain: testandc.com\nupsert_domain: cirrotester.com\nupsert_domain:\
          \ chatter.salesforce.com\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@tomr.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'paloaltonetworks.com', 'user_count': 18, 'external':\
          \ False, 'cs_user': 'service@tomr.com'}\nINFO: {'domain': u'apertureqa3.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO:\
          \ {'domain': u'gmail.com', 'user_count': 17, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'apertureqa4.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'box.com', 'user_count': 1, 'external': True, 'cs_user': 'service@tomr.com'}\n\
          INFO: {'domain': u'garlic.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'aperturesamlauto.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO:\
          \ {'domain': u'aperturead1.com', 'user_count': 4, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'apertureqa.com', 'user_count':\
          \ 128, 'external': False, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'panwcirro.onmicrosoft.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'apertureqa3.com', 'user_count':\
          \ 28, 'external': False, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'apertureqa3.onmicro', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'apertureqa2.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'probeapertureus.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'aperturead2.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'testandc.com', 'user_count': 1, 'external': True, 'cs_user': 'service@tomr.com'}\n\
          INFO: {'domain': u'boxdevedition.com', 'user_count': 26, 'external': True,\
          \ 'cs_user': 'service@tomr.com'}\nINFO: {'domain': u'cirrotester.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'hotmail.com', 'user_count': 2, 'external': True, 'cs_user': 'service@tomr.com'}\n\
          INFO: {'domain': u'xoriant.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'apertureatf.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO:\
          \ {'domain': u'apertureqa1.com', 'user_count': 6, 'external': False, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'yahoo.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain': u'outlook.com',\
          \ 'user_count': 5, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO:\
          \ {'domain': u'apertureatf.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: {'domain': u'chatter.salesforce.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@tomr.com'}\nINFO: {'domain':\
          \ u'apertureqa.onmicrosoft.com', 'user_count': 17, 'external': True, 'cs_user':\
          \ 'service@tomr.com'}\nINFO: #domains=27\n2020-02-28 19:44:32,547 MainThread\
          \ spark-domain-count-tomr: INFO: user-counts-by-domain: time to process\
          \ people table=1.14\n2020-02-28 19:44:32,547 MainThread spark-domain-count-tomr:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.17\n\
          2020-02-28 19:44:32,547 MainThread spark-domain-count-tomr: INFO: user-counts-by-domain.interval=1.32\n"
        pid: null
        result: tomr:domain-count, pid=101808 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:50:35 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:50:35 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:50:35 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:50:35 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:50:35\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:50:35 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.61340
        result: tomr:people-sort, pid=61340 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          async_download:
            enabled: 'true'
          monitoring:
            ? ''
            : null
            enabled: 'true'
          rbac_teams:
            enabled: 'true'
          service_discovery:
            ? ''
            : null
            dashboard:
              ? ''
              : null
              enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(UClNLSovk0jyyyO1mbx9j2YOor/Hw4+sgstr1SxvFoSM5+yynRQbSA==)
        POSTGRES_SCHEMA_NAME: cs_tomr
        POSTGRES_USER: ENC(9tOQ1YWH/svSwBYQqCzkRgYiWLbiMTqEeaw2jQAZCj8=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tomr
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tomr
        MONGODB_TENANTDB_PWD: ENC(KtsH4oPqrlJ53FhL6n0IKTocGtO8VUEJTcYAozMNZOrlKoXMdxPdKQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(Vn8pEbCbbtmzTiWBS7KWFm7z6U8huJdriH/amuJJK+M=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.92.2440
      fe: 4.1.186
  tomrioux:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''tomrioux'')

          2020-02-28 19:43:02,644 MainThread spark-people-sort-tomrioux: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''tomrioux'')

          20/02/28 19:43:03 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:43:03 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          '
        pid: null
        result: tomrioux:analyze-ml, pid=77319 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: ": org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Index [tomrioux_policy_detecteds/policy_detected]\
          \ missing and settings [es.field.read.empty.as.null] is set to false\n\t\
          at org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:247)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat.getSplits(EsInputFormat.java:457)\n\
          \tat org.elasticsearch.hadoop.mr.EsInputFormat.getSplits(EsInputFormat.java:438)\n\
          \tat org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:49:13 WARN EsInputFormat:\
          \ Cannot determine task id...\n20/02/28 19:49:14 WARN EsInputFormat: Cannot\
          \ determine task id...\nINFO: internal_domains==[\n    \"tomrioux.com\"\n\
          ]\n20/02/28 19:49:14 WARN EsInputFormat: Cannot determine task id...\n20/02/28\
          \ 19:49:14 WARN EsInputFormat: Cannot determine task id...\nINFO: writing\
          \ 0 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@tomrioux.com\nINFO: ------------------------------------------------\n\
          INFO: #domains=0\n2020-02-28 19:49:15,514 MainThread spark-domain-count-tomrioux:\
          \ INFO: user-counts-by-domain: time to process people table=0.68\n2020-02-28\
          \ 19:49:15,515 MainThread spark-domain-count-tomrioux: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.00\n2020-02-28 19:49:15,515 MainThread\
          \ spark-domain-count-tomrioux: INFO: user-counts-by-domain.interval=0.68\n"
        pid: null
        result: tomrioux:domain-count, pid=38022 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''tomrioux'', use_elasticsearch=False)

          2020-02-28 19:47:56,736 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tomrioux/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:47:56,741 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tomrioux/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:47:56,745 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tomrioux/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:47:56,746 MainThread spark-people-sort-tomrioux: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''tomrioux'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:47:57 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:47:57 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:47:58 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: tomrioux:people-sort, pid=19192 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(nJr65KiuV13qv6Hr7LdV0qCAx1HAmdtccWlrLCGjY5JRe0+Co3zbcw==)
        POSTGRES_SCHEMA_NAME: cs_tomrioux
        POSTGRES_USER: ENC(VK77c/L+X4KNP16G2FV3HYOtoinVNWxl5aGucdaGOPQ=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tomrioux
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tomrioux
        MONGODB_TENANTDB_PWD: ENC(F8FGvwbsvvrDYt23Ppg6GauoLHPByGLErs7op1vpreFpvav1kHqhSg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(gwD08tGb0H6Eyims4d5Mu18SwIBbGqTYOHZhM+DWZnw=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.42.1620
      fe: 3.13.d321
      worker: 3.13.42.d1986
  trioux:
    analytics:
      $disabled: 'true'
      analyze-ml:
        ? ''
        : null
        log: "20/02/28 19:45:14 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:45:14 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:45:14\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:45:14 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:45:14 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:45:14 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:45:14\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:45:14 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:45:14 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:45:14 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:45:14\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:45:14 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: trioux:analyze-ml, pid=112638 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:50:43 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:50:43 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:50:43\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:50:43 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:50:43 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:50:43 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:50:43 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:50:43\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:50:43 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:50:43 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:50:43 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:50:43 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:50:43\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:50:43 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.62418
        result: trioux:domain-count, pid=62418 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='trioux', use_elasticsearch=False)\n\
          2020-02-28 19:47:19,533 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/trioux/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:47:19,538 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/trioux/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:47:19,543 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/trioux/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:47:19,543 MainThread spark-people-sort-trioux:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='trioux', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:47:19 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:47:21 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:47:21\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:47:21 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:47:21 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          fatal: Not a git repository (or any of the parent directories): .git\nfatal:\
          \ Not a git repository (or any of the parent directories): .git\nTraceback\
          \ (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-people-sort.py\"\
          , line 186, in <module>\n    _es_owned_risks = utils.es_group_by(TENANT\
          \ + '_faceted_objects', ELASTICSEARCH, group_by='ownerable_id', exists='open_incidents')\n\
          \  File \"/opt/pan/aperture/rta/src/utils.py\", line 669, in es_group_by\n\
          \    s = _es.search(index=index, body=query)\n  File \"/usr/local/lib/python2.7/dist-packages/elasticsearch/client/utils.py\"\
          , line 69, in _wrapped\n    return func(*args, params=params, **kwargs)\n\
          \  File \"/usr/local/lib/python2.7/dist-packages/elasticsearch/client/__init__.py\"\
          , line 531, in search\n    doc_type, '_search'), params=params, body=body)\n\
          \  File \"/usr/local/lib/python2.7/dist-packages/elasticsearch/transport.py\"\
          , line 307, in perform_request\n    status, headers, data = connection.perform_request(method,\
          \ url, params, body, ignore=ignore, timeout=timeout)\n  File \"/usr/local/lib/python2.7/dist-packages/elasticsearch/connection/http_urllib3.py\"\
          , line 93, in perform_request\n    self._raise_error(response.status, raw_data)\n\
          \  File \"/usr/local/lib/python2.7/dist-packages/elasticsearch/connection/base.py\"\
          , line 105, in _raise_error\n    raise HTTP_EXCEPTIONS.get(status_code,\
          \ TransportError)(status_code, error_message, additional_info)\nelasticsearch.exceptions.NotFoundError:\
          \ TransportError(404, u'IndexMissingException[[trioux_faceted_objects] missing]')\n"
        pid: null
        result: trioux:people-sort, pid=13194 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wfm:
          enabled: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
          s3:
            OVERRIDE_WITH_GLOBAL_RATE_LIMIT: 'true'
            RATE_LIMIT_PER_SECOND_S3_API: '10'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(yHlhGMFIe6v5sO1fTjLYPJRc3UR3Y86P/j1TECY3nL3WvoXLPJRMJA==)
        POSTGRES_SCHEMA_NAME: cs_trioux
        POSTGRES_USER: ENC(vB79T62ZygPn1i2KlEQzNp/Lexw5TGkXASKqZi+qFBI=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_trioux
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_trioux
        MONGODB_TENANTDB_PWD: ENC(wkHys+dVOduBf9Mr3ZupVvtPUDJqY1HAmNVUysHDUsmDDthr3HgcHQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(2SlH28TWeYatN8sRpD2QSIig620RvTkIwRru6b3cg4Q=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      autolib: 1.57.2057
      fe: 4.1.34
      worker: 3.13.57.d4
  tsg36:
    database:
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsg36
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsg36
        MONGODB_TENANTDB_PWD: ENC(7ohVEuyJDb1Mj2wU2hUEZpx4vR0en8AJzKjWD5CGaXfTs15gYidqrQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(MLCPgbTCNmb3TWYxBkxMQvrGm7QdZRDQY40PpBdICts=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
  tsg37:
    config:
      v1:
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
    database:
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(ZvJ1a+AAeG4w+eigOzRXE1FIZtsEJZmfY0FLX8d+fe43z58u/98JfQ==)
        POSTGRES_SCHEMA_NAME: cs_tsg37
        POSTGRES_USER: ENC(za6vtqDf9BGcsqxsqBPBf2LKgF7ic6kYE66tzM0Q22E=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsg37
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsg37
        MONGODB_TENANTDB_PWD: ENC(3Z/039gqroqUl1V9PP2UeJVNn66aFyy2cEQjHKfYqrmSLMwBeFpjug==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(dgqoo3LYEfWfQJ4XeoJbRLgaJWOWqK7h9/JJjyswQz8=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
  tsg41:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
          rbac:
            local_or_sso_auth: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(m3bVC0TeQL5Z4GJDa/Iw2eZ+r241UE+4s5NKM0JByalh5b9Yk8UOrA==)
        POSTGRES_SCHEMA_NAME: cs_tsg41
        POSTGRES_USER: ENC(YnRiLds5Cl1qP+De52xvTykxrrI2bauHc9tZpLk/s5M=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsg41
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsg41
        MONGODB_TENANTDB_PWD: ENC(TMf0J/9xyOSCtLlmHy7Xz8JfZo75IwX9Mo/e8vj573ftFo7HfhzZQQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(5sj8h5f79xfopZ0ANf/iwjVv4o3dWAq1jbv4HkkLqdI=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  tsg500:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(BoCBaSJ3KakVjIpQXxS89Yi0U3jU03iCNV7PFJ8qSLN5dx5Mmk4w8w==)
        POSTGRES_SCHEMA_NAME: cs_tsg500
        POSTGRES_USER: ENC(t0qfkE8/Zh2krg7xdKfosQXKDR3nIPpYkealioZfWok=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsg500
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsg500
        MONGODB_TENANTDB_PWD: ENC(5w5h8pJcMN+UIFAo14mJw/vrPDsJs0HXMLai9+whVi1RHTJA2SshlA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(E6FIR41XOWe+hCvKv22oZnEk9nYpRm40XVmC2jBtIds=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  tsgreg01:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(tiQThFPOUHVnm7+NZ1u2biwvObOUAPSODnCryLn8yZCnHY8UChsj9w==)
        POSTGRES_SCHEMA_NAME: cs_tsgreg01
        POSTGRES_USER: ENC(UkBNie/p2j6ZltwDLTSHx5iYTmALOZVlZ0ZbUrKHggw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsgreg01
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsgreg01
        MONGODB_TENANTDB_PWD: ENC(RLpLv6ZPvQbAyWUsu6G6wtiL6w9twxCWJGioQvxVCYUkVIjyPCg+oA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(DLVeXqzVZe6twikQ2v76rqzjymBC/YYdcq1EEwPUIik=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  tsingh0226:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''tsingh0226'')

          2020-02-28 19:43:47,105 MainThread spark-people-sort-tsingh0226: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''tsingh0226'')

          20/02/28 19:43:47 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:43:48 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=tsingh0226,build=1.0.32.b145,migrated=True,tenant=tsingh0226,category=es_ip,subcategory=es_source_code:1978

          '
        pid: null
        result: tsingh0226:analyze-ml, pid=91673 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\t\
          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:43:22 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"tsingh0226.com\"\
          \n]\n20/02/28 19:43:22 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:43:22 WARN EsInputFormat: Cannot determine task id...\nINFO:\
          \ writing 23 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@tsingh0226.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'yahoo.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tsingh0226.com'}\nINFO: {'domain': u'paloaltonetworks.com', 'user_count':\
          \ 8, 'external': True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain':\
          \ u'trbvn.com', 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'apertureatf.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'hotmail.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'apertureqa3.onmicrosoft.com', 'user_count': 1, 'external':\
          \ True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'panwcirro.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'cirrosecure.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'aperturesamlauto.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'apertureqa2.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'gmail.com', 'user_count':\
          \ 10, 'external': True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain':\
          \ u'cirrotester.com', 'user_count': 2, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 17, 'external':\
          \ True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'xor.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'outlook.com', 'user_count': 5, 'external': True, 'cs_user':\
          \ 'service@tsingh0226.com'}\nINFO: {'domain': u'xoriant.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain':\
          \ u'apertureqa3.onmicro', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tsingh0226.com'}\nINFO: {'domain': u'qq.com', 'user_count': 1,\
          \ 'external': True, 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain':\
          \ u'apertureatf.com', 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@tsingh0226.com'}\nINFO: {'domain': u'apertureqa.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\n\
          INFO: {'domain': u'garlic.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@tsingh0226.com'}\nINFO: {'domain': u'apertureqa3.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@tsingh0226.com'}\nINFO: #domains=23\n\
          2020-02-28 19:43:23,351 MainThread spark-domain-count-tsingh0226: INFO:\
          \ user-counts-by-domain: time to process people table=0.82\n2020-02-28 19:43:23,351\
          \ MainThread spark-domain-count-tsingh0226: INFO: user-counts-by-domain:\
          \ time to write to mongo/elasticsearch=0.00\n2020-02-28 19:43:23,351 MainThread\
          \ spark-domain-count-tsingh0226: INFO: user-counts-by-domain.interval=0.82\n"
        pid: null
        result: tsingh0226:domain-count, pid=77740 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='tsingh0226', use_elasticsearch=False)\n\
          2020-02-28 19:47:20,130 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh0226/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:47:20,134 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh0226/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:47:20,138 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh0226/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:47:20,138 MainThread spark-people-sort-tsingh0226:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='tsingh0226', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:47:21 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:47:21 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:47:21\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:47:21 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:47:21 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:47:21 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\nfatal: Not a git repository (or any of the parent\
          \ directories): .git\n\r[Stage 0:>                                     \
          \                    (0 + 0) / 36]\r[Stage 0:>                         \
          \                               (0 + 36) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: tsingh0226:people-sort, pid=13299 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          delay_wildfire_submission_sec: '60'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        enable_policy_evaluation_logs: 'true'
        fe:
          group_based_policies:
            enabled: 'true'
          group_based_visibility:
            enabled: 'true'
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'true'
        group_based_policies:
          enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'false'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(mBH3Fty2NEtgU5IZDWeacTNhD9UnqDwh4nHcY3E4eDh8recncYVmfA==)
        POSTGRES_SCHEMA_NAME: cs_tsingh0226
        POSTGRES_USER: ENC(JK7upPtGhKxe05t5Yya7KkWTn+ZOG8r/jmzvUK8AZEw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsingh0226
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsingh0226
        MONGODB_TENANTDB_PWD: ENC(uv+nX+N210vGyFow+oDI3wsuE8YG67PFOMOadUgIu9unzEU8oTqKWw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(9TlyYXpOv7zzWN3OIhMT70NphMCZTfsOKzayrCBkSng=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: 3.13.109.4697-dev
  tsingh17:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='tsingh17')\n2020-02-28\
          \ 19:49:05,433 MainThread spark-people-sort-tsingh17: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='tsingh17')\n20/02/28 19:49:05 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:49:06 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:49:06\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:49:06 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:49:06 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:49:06 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:49:06 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:49:06\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\n20/02/28 19:49:06 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4047. Attempting port 4048.\n20/02/28 19:49:06 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n\
          20/02/28 19:49:06 WARN Utils: Service 'SparkUI' could not bind on port 4049.\
          \ Attempting port 4050.\nTraceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: tsingh17:analyze-ml, pid=38253 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:44:27 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:44:27 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:44:27 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:44:27 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:44:27\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:44:27 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: tsingh17:domain-count, pid=102649 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: 'Namespace(api_endpoint=None, bulk=10000, consul=''consul:8500'', cores=32,
          dryrun=False, engine=''elasticsearch'', engines=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''tsingh17'', use_elasticsearch=False)

          2020-02-28 19:47:20,489 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh17/apilayer/HOST,
          result=<Response [200]>

          2020-02-28 19:47:20,494 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh17/apilayer/PORT,
          result=<Response [200]>

          2020-02-28 19:47:20,501 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/tsingh17/apilayer/VERSION,
          result=<Response [200]>

          2020-02-28 19:47:20,502 MainThread spark-people-sort-tsingh17: INFO: Namespace(api_endpoint=''http://api11.dataservice.cs.stg:8080/database/write'',
          bulk=10000, consul=''consul:8500'', cores=32, dryrun=False, engine=''elasticsearch'',
          engines=''elasticsearch'', es_source=None, log_dir=''/opt/pan/aperture/rta/log'',
          log_level=''INFO'', monitoring=''stats:8225'', policy_overhaul=True, show_items=False,
          sorted=False, spark_master=''local[*]'', tenant=''tsingh17'', use_api=True,
          use_elasticsearch=False)

          20/02/28 19:47:21 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:47:22 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          fatal: Not a git repository (or any of the parent directories): .git

          fatal: Not a git repository (or any of the parent directories): .git

          http://api11.dataservice.cs.stg:8080/database/write

          '
        pid: null
        result: tsingh17:people-sort, pid=13392 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(C4qCdo4HhS2VGDVR9ahM1ZvAojgr2vo/2fzgI9UaYslem4asK1m+fQ==)
        POSTGRES_SCHEMA_NAME: cs_tsingh17
        POSTGRES_USER: ENC(tWmFtdLndhKSkYY/WNSWxqiCAm+TIEwT8tFWeFRV7SI=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsingh17
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsingh17
        MONGODB_TENANTDB_PWD: ENC(CtLOXDFVZomqh5jAMjceMO86GPn0q1Hy3VSXjKq1OZkLfQL4j3bFkA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(L18VOIIlcciqZtf3DCHmmrsD4AcmHm6hmfHyVAh/DPs=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  tsingh22:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'false'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'FALSE'
          sspm:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_rta_processing: 'False'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(kgVYk+7UzQWdwFO99qF+lmkYDnJ78olVYNQm9fp70vpVR7OK0MKTiw==)
        POSTGRES_SCHEMA_NAME: cs_tsingh22
        POSTGRES_USER: ENC(AzbylqQN0kQF7YdSG+VHOu/+io7bWV53q31VUiPBx4s=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_tsingh22
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_tsingh22
        MONGODB_TENANTDB_PWD: ENC(rjdQPBzsQpQlQVzRR+UdLJudpwlELPaGnxr+qYbjcnhOAiVYttvIGw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(2Pu3A0sCcv2EAoEpHP5sd/xaNhUbTjosJM5rHplw0U0=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fedev.706
  uebastg201:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
          rbac:
            local_or_sso_auth: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          o365:
            fetch_user_logins: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(/DklZysAnNYEE3ArxFRvxgiQlTq1VIPqYf0lPoMvz0bOiO8qMH/ihg==)
        POSTGRES_SCHEMA_NAME: cs_uebastg201
        POSTGRES_USER: ENC(iyCBb4VMYQNN6WmvC2EBP3BdTvG7/OO8x9PqzjJJqM4=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_uebastg201
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_uebastg201
        MONGODB_TENANTDB_PWD: ENC(U3Krs45Nvcsn98/4e+3eyrmZm+8mn2F2z8LPxzLCeVkFVA9hU8ovVg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(uYRq03U5Yce3IIx8oDGU6c8Yrk5un16fbf0ICJO6sO4=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.ueba.704
  uebatest:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  uebatest01:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'false'
          rbac:
            local_or_sso_auth: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(/oGDFd+ml9t7NrCX63VRgApL7DUQqZ4PYT9cOnpXriaJv3jPZCLPuA==)
        POSTGRES_SCHEMA_NAME: cs_uebatest01
        POSTGRES_USER: ENC(20x24Gzl2rN34ksncTksQkxH4D+hovSZO9mdQYo/lEc=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_uebatest01
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_uebatest01
        MONGODB_TENANTDB_PWD: ENC(q+UVJyySlStcscrlnDbeczh8AnYEIX4m8zNLSqs1fvFQ0wAWeFjJxw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(vxvlRAZE8Bfz6BLHDPNeEotmdWTrt5rPkWeCKEt9mMg=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  uebatest2:
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
  uttam1112:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='uttam1112')\n2020-02-28\
          \ 19:49:05,801 MainThread spark-people-sort-uttam1112: INFO: Namespace(consul='consul:8500',\
          \ data_patterns_service='data-pattern-service', duration=None, es_source=None,\
          \ log_dir='/opt/pan/aperture/rta/log', log_level='INFO', monitoring='stats:8225',\
          \ spark_master='local', tenant='uttam1112')\n20/02/28 19:49:06 WARN NativeCodeLoader:\
          \ Unable to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:49:07\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:49:07 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:49:07 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:49:07\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4047. Attempting port 4048.\n20/02/28 19:49:07 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n\
          20/02/28 19:49:07 WARN Utils: Service 'SparkUI' could not bind on port 4049.\
          \ Attempting port 4050.\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4050. Attempting port 4051.\n20/02/28 19:49:07\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting\
          \ port 4052.\n20/02/28 19:49:07 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4052. Attempting port 4053.\n20/02/28 19:49:07 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4053. Attempting port 4054.\n\
          Traceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: uttam1112:analyze-ml, pid=38511 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:46:46 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"uttam1112.com\"\
          \n]\n20/02/28 19:46:46 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:46:46 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 3:=============================>                             (1 + 1) /\
          \ 2]\r                                                                 \
          \               \rINFO: writing 19 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@uttam1112.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'yahoo.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@uttam1112.com'}\nINFO: {'domain': u'paloaltonetworks.com', 'user_count':\
          \ 7, 'external': True, 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain':\
          \ u'cirrotester.com', 'user_count': 2, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'hotmail.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@uttam1112.com'}\nINFO: {'domain': u'trbvn.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain':\
          \ u'boxdevedition.com', 'user_count': 22, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'cirrosecure.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain': u'aperturead1.com',\
          \ 'user_count': 3, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'gmail.com', 'user_count': 8, 'external': True, 'cs_user':\
          \ 'service@uttam1112.com'}\nINFO: {'domain': u'apertureqa3.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'apertureqa.onmicrosoft.com', 'user_count': 3, 'external':\
          \ True, 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain': u'xor.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'outlook.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@uttam1112.com'}\nINFO: {'domain': u'garlic.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain':\
          \ u'xoriant.com', 'user_count': 2, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'qq.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@uttam1112.com'}\nINFO: {'domain': u'apertureqa1.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@uttam1112.com'}\nINFO: {'domain':\
          \ u'apertureqa.com', 'user_count': 1, 'external': True, 'cs_user': 'service@uttam1112.com'}\n\
          INFO: {'domain': u'apertureqa3.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@uttam1112.com'}\nINFO: #domains=19\n2020-02-28 19:46:48,105\
          \ MainThread spark-domain-count-uttam1112: INFO: user-counts-by-domain:\
          \ time to process people table=1.59\n2020-02-28 19:46:48,106 MainThread\
          \ spark-domain-count-uttam1112: INFO: user-counts-by-domain: time to write\
          \ to mongo/elasticsearch=0.00\n2020-02-28 19:46:48,106 MainThread spark-domain-count-uttam1112:\
          \ INFO: user-counts-by-domain.interval=1.60\n"
        pid: null
        result: uttam1112:domain-count, pid=7969 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: null
        pid: ip-10-3-7-96.77853
        result: 'action: state=running'
        state: running
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(Iyq+CsqqfISCm9bgcdH5ra5qN0yKQDl27qTRaazAgGGTivDBn/qIsw==)
        POSTGRES_SCHEMA_NAME: cs_uttam1112
        POSTGRES_USER: ENC(bOCOtDyx7hkmQDvcvnQp6K9Q9/xwcVR/92Gf2w7dhLw=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_uttam1112
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_uttam1112
        MONGODB_TENANTDB_PWD: ENC(8cuLNW/FKYrxA+ddVaroLdWeNHwpxJD7OLAPQ5CdyhSpDGSas5yHeA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(ic3l1IiaOHT6EzL5jHrryKldmHNznYa26sNtxmTMvSc=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  uttamfotest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(/m68bhfDRALpw20stAO5dDIKeaDneFQZqAFKSerOeLESb73nYsKwjA==)
        POSTGRES_SCHEMA_NAME: cs_uttamfotest
        POSTGRES_USER: ENC(CmjnUkccG6l+oZODIHjHe3hcD7TkztjBwHjwWpqO/ZU=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_uttamfotest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_uttamfotest
        MONGODB_TENANTDB_PWD: ENC(90gr3YVb9EyAnwF4HP60kXiI2pOAw6Pikd7trDrsGK8P9DIVWT1TOA==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(yYutJo09NgSmIr5dw/DA0su8weArMprI/Ta71xc1z9s=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fo.854
  uttammigration:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: "Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='uttammigration')\n\
          2020-02-28 19:45:54,025 MainThread spark-people-sort-uttammigration: INFO:\
          \ Namespace(consul='consul:8500', data_patterns_service='data-pattern-service',\
          \ duration=None, es_source=None, log_dir='/opt/pan/aperture/rta/log', log_level='INFO',\
          \ monitoring='stats:8225', spark_master='local', tenant='uttammigration')\n\
          20/02/28 19:45:54 WARN NativeCodeLoader: Unable to load native-hadoop library\
          \ for your platform... using builtin-java classes where applicable\n20/02/28\
          \ 19:45:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting\
          \ port 4041.\n20/02/28 19:45:55 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4041. Attempting port 4042.\n20/02/28 19:45:55 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n\
          20/02/28 19:45:55 WARN Utils: Service 'SparkUI' could not bind on port 4043.\
          \ Attempting port 4044.\n20/02/28 19:45:55 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:45:55\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:45:55 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:45:55 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          Traceback (most recent call last):\n  File \"/opt/pan/aperture/rta/src/spark-analyze-ml.py\"\
          , line 127, in <module>\n    dp_map = dict([(v['id'], {'category': v['category_type'],\
          \ 'subcategory': v['type'], 'name': v['name']}) for v in dp['resources']])\n\
          KeyError: 'category_type'\n"
        pid: null
        result: uttammigration:analyze-ml, pid=124368 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "20/02/28 19:50:45 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:50:45 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:50:45\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:50:45 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:50:45 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:50:45 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:50:45 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:50:45\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:50:45 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:50:45 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:50:45 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:50:45 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:50:45\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:50:45 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: ip-10-3-7-96.62697
        result: uttammigration:domain-count, pid=62697 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "20/02/28 19:50:00 WARN Utils: Service 'SparkUI' could not bind on port\
          \ 4043. Attempting port 4044.\n20/02/28 19:50:00 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4044. Attempting port 4045.\n20/02/28 19:50:00\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting\
          \ port 4046.\n20/02/28 19:50:00 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4046. Attempting port 4047.\n20/02/28 19:50:00 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n\
          20/02/28 19:50:00 WARN Utils: Service 'SparkUI' could not bind on port 4048.\
          \ Attempting port 4049.\n20/02/28 19:50:00 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4049. Attempting port 4050.\n20/02/28 19:50:00\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting\
          \ port 4051.\n20/02/28 19:50:00 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4051. Attempting port 4052.\n20/02/28 19:50:00 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n\
          20/02/28 19:50:00 WARN Utils: Service 'SparkUI' could not bind on port 4053.\
          \ Attempting port 4054.\n20/02/28 19:50:00 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4054. Attempting port 4055.\n20/02/28 19:50:00\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting\
          \ port 4056.\n20/02/28 19:50:00 ERROR SparkUI: Failed to bind SparkUI\n\
          java.net.BindException: Address already in use: Service 'SparkUI' failed\
          \ after 16 retries! Consider explicitly setting the appropriate port for\
          \ the service 'SparkUI' (for example spark.ui.port for SparkUI) to an available\
          \ port or increasing spark.port.maxRetries.\n\tat sun.nio.ch.Net.bind0(Native\
          \ Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\
          \tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\
          \tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\t\
          at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)\n\
          \tat org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)\n\
          \tat org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)\n\
          \tat org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.spark_project.jetty.server.Server.doStart(Server.java:366)\n\t\
          at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)\n\
          \tat org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)\n\
          \tat org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2091)\n\
          \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\t\
          at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2082)\n\t\
          at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)\n\
          \tat org.apache.spark.ui.WebUI.bind(WebUI.scala:139)\n\tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:448)\n\
          \tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:448)\n\
          \tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\
          \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\
          \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\t\
          at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\
          \tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\
          \tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
        pid: null
        result: uttammigration:people-sort, pid=51375 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: v4
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(EII2ULk7R6UtzAyz6H+cRc2dbjOYPSoGgglbwobvt5BBXDXAX2qiZg==)
        POSTGRES_SCHEMA_NAME: cs_uttammigration
        POSTGRES_USER: ENC(6FjkpxB/CWRxp4XMQqTIGdaDI+puy+tJ50xtLgIxWZs=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_uttammigration
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_uttammigration
        MONGODB_TENANTDB_PWD: ENC(z0kN9TaTH0zK/2wNUt+R3wU8foqOftzBTKZx51r95IPfLo/rV+8Jkw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(OfOW73eabhABUv0qV/31l/kbOLCfxLV51WMpcVxnu9w=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.dss.655
  vramu:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          print-dss-report-in-logs: 'false'
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
        fe:
          pan_sso:
            enabled: 'True'
          show_dlp_licensing_prompt:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        wildfire_cache_service_enabled: 'true'
        worker:
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(6gYFzHtxvq+C6Zd+jTbhx2t9RpB37CI0rhQzexGA45qe/n3LnRdxpg==)
        POSTGRES_SCHEMA_NAME: cs_vramu
        POSTGRES_USER: ENC(CsrFH8nfyyVGHPPvJbyPYkz+nuk1gD5GXbbSh9+qRIs=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_vramu
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_vramu
        MONGODB_TENANTDB_PWD: ENC(dN1oArinza9b2U8X36OWZtVh7xu/LkNJE+DFKoT0Xvpf1CNf4iFl8A==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(PU1l8oi7pTnOvizYyONZ5WkgF3/VLrbMEaKwdKD9PKI=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: null
  wilin:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
          sspm:
            enabled: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      fe: 0.0.fedev.653
  xsoar-integration:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  xsoarsupport:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          advanced_inline:
            enabled: 'false'
          advanced_saas_visibility:
            enabled: 'false'
          asv_only:
            enabled: 'false'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(bq4YBWY7lp/JZWb5gSCrroDvfR0any9kOKtaZmEBCsnV6RY2BRtn/Q==)
        POSTGRES_SCHEMA_NAME: cs_xsoarsupport
        POSTGRES_USER: ENC(XRKWnTITDWO3MBSNGAWfp31eowC2JHAGw8PJG5ccq7Q=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_xsoarsupport
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_xsoarsupport
        MONGODB_TENANTDB_PWD: ENC(XxEM50+qeImMG3m9GN7LZ7Woldu79wcnsWbKoNkYEvPtqtnEiCRYuw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(UoDzZw03LbKKsNI5LDUXc9JPI3X0SPTNTYMzS4N3DCE=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: 3.13.41.5563-dev
  xsoartest:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'false'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          dss-enabled: 'false'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wfm:
          enabled: 'true'
          expanded_types_enabled: 'true'
          malware_analysis_status_enabled: 'true'
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(+CSHv7/J3Xt6EvzPlxhT//6qVaw5m6OWRFPH8nMdthyOBvzsvNfhnA==)
        POSTGRES_SCHEMA_NAME: cs_xsoartest
        POSTGRES_USER: ENC(73KwosPCIcSCFovolcgpxrHkuYbHwPXaKADRbdNn2Ys=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_xsoartest
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_xsoartest
        MONGODB_TENANTDB_PWD: ENC(ffFJXQdBhIcKtImk6XV92RDgmLC156T5GaRTz8/DaqNjBxSH/APmzQ==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(dLtMSr69uJG2c/0tRVTcwTj+cd/1vdUPKHf0uY4Fiag=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: 3.13.41.5520-dev
  zhiwang:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''zhiwang'')

          2020-02-28 19:48:17,558 MainThread spark-people-sort-zhiwang: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''zhiwang'')

          20/02/28 19:48:17 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:48:18 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=zhiwang,build=1.0.32.b145,migrated=True,tenant=zhiwang,category=es_ip,subcategory=es_source_code:3271

          '
        pid: null
        result: zhiwang:analyze-ml, pid=23557 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\n20/02/28 19:46:48 WARN EsInputFormat: Cannot determine task id...\n\
          INFO: internal_domains==[\n    \"stg3appstenant.com\", \n    \"apertureqa3.com\"\
          , \n    \"paloaltonetworks.com\", \n    \"apertureqa7.onmicrosoft.com\"\n\
          ]\n20/02/28 19:46:50 WARN EsInputFormat: Cannot determine task id...\n20/02/28\
          \ 19:46:50 WARN EsInputFormat: Cannot determine task id...\n\r[Stage 3:=============================>\
          \                             (1 + 1) / 2]\r                           \
          \                                                     \rINFO: writing 32\
          \ domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@zhiwang.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'yahoo.co.in', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'yahoo.com', 'user_count': 4,\
          \ 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'paloaltonetworks.com', 'user_count': 21, 'external': False, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'apertureqa3.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'apertureqa5.onmicrosoft.com', 'user_count': 1014, 'external':\
          \ True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain': u'hotmail.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'apertureqa4.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain': u'trbvn.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'cirrosecure.com', 'user_count': 2, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'boxdevedition.com', 'user_count': 3, 'external': True,\
          \ 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain': u'apertureqa7.onmicrosoft.com',\
          \ 'user_count': 2, 'external': False, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'external.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'gmail.com', 'user_count': 22,\
          \ 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'probeapertureus.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'cirrotester.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'asd.com', 'user_count': 2, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'alksjdslkd.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'apertureqa.onmicrosoft.com',\
          \ 'user_count': 4, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'xor.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'outlook.com', 'user_count':\
          \ 1, 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'apertureqa1.com', 'user_count': 3, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'lklk.com', 'user_count': 1, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'aperturesync.onmicrosoft.com',\
          \ 'user_count': 2, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'garlic.com', 'user_count': 2, 'external': True, 'cs_user':\
          \ 'service@zhiwang.com'}\nINFO: {'domain': u'box.com', 'user_count': 1,\
          \ 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'qq.com', 'user_count': 1, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'apertureatf.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain': u'xoriant.com', 'user_count':\
          \ 2, 'external': True, 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain':\
          \ u'apertureqa.com', 'user_count': 27, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'aperturead2.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@zhiwang.com'}\nINFO: {'domain': u'prismasaasdev.com',\
          \ 'user_count': 4, 'external': True, 'cs_user': 'service@zhiwang.com'}\n\
          INFO: {'domain': u'apertureqa3.com', 'user_count': 3, 'external': False,\
          \ 'cs_user': 'service@zhiwang.com'}\nINFO: #domains=32\n2020-02-28 19:46:54,812\
          \ MainThread spark-domain-count-zhiwang: INFO: user-counts-by-domain: time\
          \ to process people table=4.77\n2020-02-28 19:46:54,812 MainThread spark-domain-count-zhiwang:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:46:54,812 MainThread spark-domain-count-zhiwang: INFO: user-counts-by-domain.interval=4.77\n"
        pid: null
        result: zhiwang:domain-count, status=zombie, state=finished
        state: finished
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='zhiwang', use_elasticsearch=False)\n\
          2020-02-28 19:44:30,756 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/zhiwang/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:44:30,762 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/zhiwang/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:44:30,765 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/zhiwang/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:44:30,766 MainThread spark-people-sort-zhiwang:\
          \ INFO: Namespace(api_endpoint='http://internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='zhiwang', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:44:31 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:44:31 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:44:31\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:44:31 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:44:31 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          fatal: Not a git repository (or any of the parent directories): .git\nfatal:\
          \ Not a git repository (or any of the parent directories): .git\n\r[Stage\
          \ 0:>                                                         (0 + 0) /\
          \ 36]\r[Stage 0:>                                                      \
          \  (0 + 36) / 36]\r[Stage 0:===>                                       \
          \              (2 + 34) / 36]\r[Stage 0:=========>                     \
          \                          (6 + 30) / 36]\r[Stage 0:==============>    \
          \                                      (9 + 27) / 36]\r[Stage 0:===============>\
          \                                        (10 + 26) / 36]\r[Stage 0:========================>\
          \                               (16 + 20) / 36]\r[Stage 0:=============================>\
          \                          (19 + 17) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:================================>\
          \                       (21 + 15) / 36]\r[Stage 0:===================================>\
          \                    (23 + 13) / 36]\r[Stage 0:=====================================>\
          \                  (24 + 12) / 36]\r[Stage 0:==========================================>\
          \              (27 + 9) / 36]\r[Stage 0:===============================================>\
          \         (30 + 6) / 36]\r[Stage 0:=================================================>\
          \       (31 + 5) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=======================================================>\
          \ (35 + 1) / 36]\r                                                     \
          \                           \rhttp://internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com:8080/database/write\n"
        pid: null
        result: zhiwang:people-sort, pid=104402 bad process, setting state=unknown
        state: unknown
    apilayer:
      HOST: internal-csstg-api-lb-402574010.us-east-1.elb.amazonaws.com
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          enable_async_incident_creation: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          cloudapp_health_metrics:
            enabled: 'true'
          health_check:
            enabled: 'false'
          pan_sso:
            enabled: 'false'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_rta_processing: 'False'
        slack:
          refresh_channel_exposure_frequency_in_min: '120'
        slurper_enabled: 'false'
        versions:
          ? ''
          : null
          worker_tag: base
        wildfire_cache_service_enabled: 'true'
        worker:
          ? ''
          : null
          exchange:
            ? ''
            : null
            ENABLE_INTERNAL_EMAIL_SCAN: 'true'
            ENABLE_INTERNAL_EMAIL_WITH_ATTACHMENTS_SCAN: 'true'
          gmail:
            GMAIL_USER_REFRESH_IN_HRS: '10'
            user_scan_interval_in_minutes: '300'
          google:
            ? ''
            : null
            max_api_calls_per_unit: '3'
            process_shared_drives: 'true'
          metrics:
            office365:
              o365_oneDrive: '700'
          processing_mode: REMEDIATION_ONLY
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(aTX0t+MNyoh+67k3BOzX5tVHy7v2MQrbEXKCqIdCJsTCXYfd806f7g==)
        POSTGRES_SCHEMA_NAME: cs_zhiwang
        POSTGRES_USER: ENC(fwm+kI+Bou5APNa9+w2UjGy913iBHOaVrquD/SehsVc=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_zhiwang
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_zhiwang
        MONGODB_TENANTDB_PWD: ENC(yxy+WAnwVc5Er1iULFYuoLaBPstOKKU7syR4NRU1LXP56JTSDm8NWg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(3Ghj6dK7c2whDRbZud+UOkL8z1qmdOESCwgGEeVabho=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      ? ''
      : null
      fe: 0.0.sysui.163
      worker: 3.13.124.d3
  zhiwang55:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        REMEDIATION_DIGEST_EMAIL_FREQUENCY: HOURLY
        data-pattern:
          data_policy_email_digest: 'true'
          enable_incidents_count_query_timeout: 'True'
          incidents_count_query_timeout_in_secs: '1'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
          skip_incidents_count_query: 'False'
        data_patterns_scan_enabled: 'true'
        dp-scan:
          return-aperture-results-details: 'false'
          return-dss-results: 'true'
          submit-to-aperture-engine: 'false'
          submit-to-dss-engine: 'true'
        dss:
          dss-enabled: 'true'
          ocr-enabled: 'false'
        fe:
          cloudapp_health_metrics:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'False'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        servicenow:
          enable_concurrent_api_calls: 'true'
        skip_policy_scheduling: 'False'
        slurper_enabled: 'false'
        versions:
          fe: 0.0.sysui.es7.166
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
        worker:
          dss:
            ocr-enabled: 'true'
          exchange:
            SCAN_FOLDER_PAGE_SIZE: '15'
            SCAN_MESSAGE_PAGE_SIZE: '25'
          gmail:
            user_scan_interval_in_minutes: '5'
          o365:
            enable_active_list_scheduling: 'false'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(TkjPtAwISSH2Kfl/JXeXyz7Nws4HJsMyIU/dCQIjfswPS5hQrwB7oQ==)
        POSTGRES_SCHEMA_NAME: cs_zhiwang55
        POSTGRES_USER: ENC(IBoE0u4oOULwpftbIJDRZ4fciZ42+oXIQjvqWkC/hyE=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_zhiwang55
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_zhiwang55
        MONGODB_TENANTDB_PWD: ENC(Hq7g3EnoNmKH6cRzqEgy6FCXXglcitja7q7k9m5R1oGw7Q+6vmM7Yw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(nqbSC+S0gm+07Hdda+cztyCbCJLSQddv03ka7z9GrnQ=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    fetch_snippets_metadata_from_dp_results: 'True'
    fetch_snippets_without_subscription: 'True'
    versions:
      dss:
        ocr-enabled: 'true'
      fe: 4.1.535-es7
      worker: 3.13.41.5542-dev
  zhiwang7:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
  zhiwanges7:
    analytics:
      $disabled: 'true'
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          dlp_licensing:
            show_prompt: 'false'
          pan_sso:
            enabled: 'True'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: null
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(AV9OlItVSECbs89SOdOf7KexWbun8btC3CNWf0IBmuQCGBgMXzPrww==)
        POSTGRES_SCHEMA_NAME: cs_zhiwanges7
        POSTGRES_USER: ENC(9UMZEujwbe2J3hUOmWFc09I9R4tJWnHCKVzJvSWB9hM=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_zhiwanges7
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_zhiwanges7
        MONGODB_TENANTDB_PWD: ENC(Yk3jZf90aXqKB2P3gkYTsgrfPkwRE5mVHzp/NZ6u4VsGKux7pKrpSw==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(4XVCpBBf6hq1gyuqARZY0SJD1JmuQfv7OjQMTnVNgdE=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_HOST: null
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      worker: 3.13.41.4854-dev
  zsajid:
    analytics:
      analyze-ml:
        ? ''
        : null
        log: 'Namespace(consul=''consul:8500'', data_patterns_service=''data-pattern-service'',
          duration=None, es_source=None, log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'',
          monitoring=''stats:8225'', spark_master=''local'', tenant=''zsajid'')

          2020-02-28 19:49:07,644 MainThread spark-people-sort-zsajid: INFO: Namespace(consul=''consul:8500'',
          data_patterns_service=''data-pattern-service'', duration=None, es_source=None,
          log_dir=''/opt/pan/aperture/rta/log'', log_level=''INFO'', monitoring=''stats:8225'',
          spark_master=''local'', tenant=''zsajid'')

          20/02/28 19:49:08 WARN NativeCodeLoader: Unable to load native-hadoop library
          for your platform... using builtin-java classes where applicable

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4040. Attempting port 4041.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4041. Attempting port 4042.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4042. Attempting port 4043.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4043. Attempting port 4044.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4044. Attempting port 4045.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4045. Attempting port 4046.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4046. Attempting port 4047.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4047. Attempting port 4048.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4048. Attempting port 4049.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4049. Attempting port 4050.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4050. Attempting port 4051.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4051. Attempting port 4052.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4052. Attempting port 4053.

          20/02/28 19:49:08 WARN Utils: Service ''SparkUI'' could not bind on port
          4053. Attempting port 4054.

          elasticsearch.keywords,host=ip-10-3-7-96,tenant=zsajid,build=1.0.32.b145,migrated=True,tenant=zsajid,category=es_ip,subcategory=es_source_code:1338

          '
        pid: null
        result: zsajid:analyze-ml, pid=39020 bad process, setting state=unknown
        state: unknown
      domain-count:
        ? ''
        : null
        log: "\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\
          \tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\
          \tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1303)\n\t\
          at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\
          \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\
          \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1298)\n\
          \tat org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:203)\n\
          \tat org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:582)\n\
          \tat org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)\n\
          \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\
          \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\
          \tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\
          \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\
          \tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\
          \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\
          \tat java.lang.Thread.run(Thread.java:748)\n\n\n20/02/28 19:45:59 WARN EsInputFormat:\
          \ Cannot determine task id...\nINFO: internal_domains==[\n    \"zsajid.com\"\
          \n]\n20/02/28 19:46:00 WARN EsInputFormat: Cannot determine task id...\n\
          20/02/28 19:46:00 WARN EsInputFormat: Cannot determine task id...\n\r[Stage\
          \ 3:=============================>                             (1 + 1) /\
          \ 2]\r                                                                 \
          \               \rINFO: writing 10 domains to Mongo\nINFO: ------------------------------------------------\n\
          INFO: user counts by domain: service@zsajid.com\nINFO: ------------------------------------------------\n\
          INFO: {'domain': u'probeapertureus.com', 'user_count': 1, 'external': True,\
          \ 'cs_user': 'service@zsajid.com'}\nINFO: {'domain': u'apertureqa.onmicrosoft.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@zsajid.com'}\n\
          INFO: {'domain': u'boxdevedition.com', 'user_count': 5, 'external': True,\
          \ 'cs_user': 'service@zsajid.com'}\nINFO: {'domain': u'paloaltonetworks.com',\
          \ 'user_count': 18, 'external': True, 'cs_user': 'service@zsajid.com'}\n\
          INFO: {'domain': u'gmail.com', 'user_count': 5, 'external': True, 'cs_user':\
          \ 'service@zsajid.com'}\nINFO: {'domain': u'apertureqa.com', 'user_count':\
          \ 3, 'external': True, 'cs_user': 'service@zsajid.com'}\nINFO: {'domain':\
          \ u'apertureqa3.com', 'user_count': 3, 'external': True, 'cs_user': 'service@zsajid.com'}\n\
          INFO: {'domain': u'apertureatf.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@zsajid.com'}\nINFO: {'domain': u'prismasaasdev.com',\
          \ 'user_count': 1, 'external': True, 'cs_user': 'service@zsajid.com'}\n\
          INFO: {'domain': u'apertureqa1.com', 'user_count': 2, 'external': True,\
          \ 'cs_user': 'service@zsajid.com'}\nINFO: #domains=10\n2020-02-28 19:46:01,256\
          \ MainThread spark-domain-count-zsajid: INFO: user-counts-by-domain: time\
          \ to process people table=0.99\n2020-02-28 19:46:01,256 MainThread spark-domain-count-zsajid:\
          \ INFO: user-counts-by-domain: time to write to mongo/elasticsearch=0.00\n\
          2020-02-28 19:46:01,256 MainThread spark-domain-count-zsajid: INFO: user-counts-by-domain.interval=1.00\n"
        pid: null
        result: zsajid:domain-count, pid=125008 bad process, setting state=unknown
        state: unknown
      faceted-join:
        ? ''
        : null
        log: null
        pid: null
        result: ready
        state: ready
      people-sort:
        ? ''
        : null
        log: "Namespace(api_endpoint=None, bulk=10000, consul='consul:8500', cores=32,\
          \ dryrun=False, engine='elasticsearch', engines=None, es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='zsajid', use_elasticsearch=False)\n\
          2020-02-28 19:46:49,337 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/zsajid/apilayer/HOST,\
          \ result=<Response [200]>\n2020-02-28 19:46:49,341 MainThread utils-default:\
          \ DEBUG: url=http://consul:8500/v1/kv/tenant/zsajid/apilayer/PORT, result=<Response\
          \ [200]>\n2020-02-28 19:46:49,345 MainThread utils-default: DEBUG: url=http://consul:8500/v1/kv/tenant/zsajid/apilayer/VERSION,\
          \ result=<Response [200]>\n2020-02-28 19:46:49,345 MainThread spark-people-sort-zsajid:\
          \ INFO: Namespace(api_endpoint='http://api11.dataservice.cs.stg:8080/database/write',\
          \ bulk=10000, consul='consul:8500', cores=32, dryrun=False, engine='elasticsearch',\
          \ engines='elasticsearch', es_source=None, log_dir='/opt/pan/aperture/rta/log',\
          \ log_level='INFO', monitoring='stats:8225', policy_overhaul=True, show_items=False,\
          \ sorted=False, spark_master='local[*]', tenant='zsajid', use_api=True,\
          \ use_elasticsearch=False)\n20/02/28 19:46:49 WARN NativeCodeLoader: Unable\
          \ to load native-hadoop library for your platform... using builtin-java\
          \ classes where applicable\n20/02/28 19:46:50 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4040. Attempting port 4041.\n20/02/28 19:46:50\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting\
          \ port 4042.\n20/02/28 19:46:50 WARN Utils: Service 'SparkUI' could not\
          \ bind on port 4042. Attempting port 4043.\n20/02/28 19:46:50 WARN Utils:\
          \ Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n\
          20/02/28 19:46:50 WARN Utils: Service 'SparkUI' could not bind on port 4044.\
          \ Attempting port 4045.\n20/02/28 19:46:50 WARN Utils: Service 'SparkUI'\
          \ could not bind on port 4045. Attempting port 4046.\n20/02/28 19:46:50\
          \ WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting\
          \ port 4047.\nfatal: Not a git repository (or any of the parent directories):\
          \ .git\nfatal: Not a git repository (or any of the parent directories):\
          \ .git\n\r[Stage 0:>                                                   \
          \     (0 + 36) / 36]\r[Stage 0:====>                                   \
          \                 (3 + 33) / 36]\r[Stage 0:=================>          \
          \                            (11 + 25) / 36]\r[Stage 0:=====================>\
          \                                  (14 + 22) / 36]\r[Stage 0:==========================>\
          \                             (17 + 19) / 36]\r[Stage 0:===============================>\
          \                        (20 + 16) / 36]\r[Stage 0:=============================================>\
          \           (29 + 7) / 36]\r[Stage 0:==================================================>\
          \      (32 + 4) / 36]\r[Stage 0:====================================================>\
          \    (33 + 3) / 36]\r[Stage 0:=====================================================>\
          \   (34 + 2) / 36]\r                                                   \
          \                             \rhttp://api11.dataservice.cs.stg:8080/database/write\n"
        pid: null
        result: zsajid:people-sort, pid=10248 bad process, setting state=unknown
        state: unknown
    apilayer:
      ES_DATA_MIGRATION_INPROGRESS: 'False'
      ES_TIMESTAMPS:
        ? ''
        : null
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_1X: 'False'
      WRITE_TO_ES_7X: 'True'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        dss:
          ? ''
          : null
          dss-enabled: 'false'
        es_index_settings:
          index_shards:
            ASSETS: '3'
        fe:
          advanced_saas_visibility:
            executive_report_max_per_day: '15'
          pan_sso:
            enabled: 'false'
          service_discovery:
            ? ''
            : null
            custom_tags: dashboard-service:es7x/data-pattern:es7x/remediation:es7x/data-policy-violation:es7x
            enabled: 'true'
        incidents:
          read_from_incidents_all: 'true'
          write_to_incidents_all: 'true'
        skip_policy_scheduling: 'True'
        skip_rta_processing: 'False'
        versions:
          ? ''
          : null
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    dashboard-service:
      ? ''
      : null
      ES_VERSION: '"7X"'
    database:
      elasticsearch:
        CLUSTER_NAME: csstg
        ES_QUERY_HOST: 10.3.0.76
        QUERY_HOST: esq.cs.stg
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
      postgres:
        POSTGRES_DB_NAME: LIT6244
        POSTGRES_HOST: lit-6244.cuip3y07n3ju.us-east-1.rds.amazonaws.com
        POSTGRES_PORT: '5432'
        POSTGRES_PWD: ENC(WU5M0GexFQS5lLK975L5Llc07YKqjZg5gIHMPCJ1NRyWUTkfNszm/w==)
        POSTGRES_SCHEMA_NAME: cs_zsajid
        POSTGRES_USER: ENC(pv7r1fNFQu1pienrqqP8v6NVcbL98PwG/DwnAWzTnWo=)
      sharded_mongodb:
        MONGODB_AUTH_DB_NAME: cs_zsajid
        MONGODB_HOST: dpmongos0,dpmongos1,dpmongos2
        MONGODB_TENANTDB_FORCE_PRIMARY_READ: 'false'
        MONGODB_TENANTDB_NAME: cs_zsajid
        MONGODB_TENANTDB_PWD: ENC(JJQiWn/KhvHt3M5SRFNDgZi6oyyMoH9A69/3CCXG2MwCWZgLm6MuYg==)
        MONGODB_TENANTDB_SSL_ENABLED: 'true'
        MONGODB_TENANTDB_USER: ENC(Htt5GAcvyE3cRA2j6z1Bxv6pw1AuN2g9vCfNDYZJnOM=)
        MONGODB_TENANTDB_WRITE_CONCERN: '1'
    elasticsearch:
      CLUSTER_NAME: csstg
      ES_QUERY_HOST: ip-10-3-0-76.ec2.internal
      QUERY_HOST: esq.cs.stg
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
    versions:
      ? ''
      : null
      fe: 0.0.es7x.no.2020.06.12.59
      worker: 3.13.41.3766-dev
  zsajiddev:
    analytics:
      domain-count:
        ? ''
        : null
      people-sort:
        ? ''
        : null
    apilayer:
      HOST: api11.dataservice.cs.stg
      PORT: '8080'
      VERSION: '1.1'
      WRITE_TO_ES_7X: 'true'
    config:
      v1:
        data-pattern:
          data_policy_email_digest: 'true'
          legacy_risks_disabled: 'true'
          resolve_incidents: 'true'
          resolve_risks: 'false'
          save_pattern_results: 'true'
          save_po_features_to_fo: 'true'
        data_patterns_scan_enabled: 'true'
        fe:
          active_directory:
            enabled: 'true'
          advanced_inline:
            enabled: 'true'
          advanced_saas_visibility:
            enabled: 'true'
          asv_only:
            enabled: 'true'
          dlp_licensing:
            show_prompt: 'false'
          gamma:
            enabled: 'false'
          pan_sso:
            enabled: 'true'
        versions:
          worker_tag: es7x
        wildfire_cache_service_enabled: 'true'
    database:
      elasticsearch:
        CLUSTER_NAME: stg2-elasticsearch7-1
        ES_QUERY_HOST: 10.3.0.76
        QUERY_PORT: '9200'
        TRANSPORT_PORT: '9300'
      kafka:
        BOOTSTRAP_SERVERS: kafka2-1.kafka.cs.stg:9092,kafka2-2.kafka.cs.stg:9092,kafka2-3.kafka.cs.stg:9092
        CLUSTER_NUMBER: '1'
      mongodb:
        MONGODB_HOST: rs1/rs1-1,rs1-2,rs1-3
        MONGODB_TENANTDB_PWD: ENC(NxKYH0wIAg3V+kPD8bzlyewe/jp1VcbD+nRjOKaX42FFZDRobSZEKA==)
        MONGODB_TENANTDB_USER: ENC(v2eb9nb13brZGSKmvV5WDWZZVv1JzutO)
    elasticsearch:
      CLUSTER_NAME: stg2-elasticsearch7-1
      ES_QUERY_HOST: 10.3.0.76
      QUERY_PORT: '9200'
      TRANSPORT_PORT: '9300'
